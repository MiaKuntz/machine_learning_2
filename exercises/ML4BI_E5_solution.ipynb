{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiaKuntz/machine_learning_2/blob/main/ML4BI_E5_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zinulpqHHyl"
      },
      "source": [
        "# Machine Learning for BI 2\n",
        "\n",
        "## Deep Learning exercises for week 6\n",
        "\n",
        "In this exercise, you will expand last weeks exercise by training pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHFM1Y-uImxl"
      },
      "source": [
        "**About the CIFAR-10 dataset**\n",
        "\n",
        "The CIFAR-10 dataset is a widely-used dataset for benchmarking machine learning algorithms, especially in the field of image recognition. It consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class. The dataset is divided into 50,000 training images and 10,000 test images. The classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. Each image is labeled with one of these 10 classes, making it a standard dataset for evaluating algorithms for image classification tasks.\n",
        "\n",
        "The CIFAR-10 dataset was created by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton and is a subset of the 80 million tiny images dataset. Due to its moderate size and complexity, CIFAR-10 serves as an excellent benchmark for algorithms and techniques in computer vision, particularly for methodologies that are aimed at performing well on small to medium-sized datasets in image recognition tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JmVDbiVHlHz"
      },
      "source": [
        "**Load and prepare the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuJGtbWHG5s3",
        "outputId": "679124dc-a70b-45a0-c9f1-af03d1a745e1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # importing the tensorflow library\n",
        "from tensorflow import keras # importing the keras library from tensorflow\n",
        "from tensorflow.keras.utils import to_categorical # importing the to_categorical function from the keras.utils module\n",
        "from tensorflow.keras import datasets, layers, models # importing the datasets, layers, and models modules from the keras library\n",
        "import matplotlib.pyplot as plt # importing the matplotlib.pyplot library\n",
        "\n",
        "# loading the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data() # loading the CIFAR-10 dataset into the train_images, train_labels, test_images, and test_labels variables respectively \n",
        "\n",
        "# assigning class names in the CIFAR-10 dataset\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck'] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "454tLLAEd6d3"
      },
      "source": [
        "**Plot images**\n",
        "\n",
        "Plot some images from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "-RxVuli4bdi0",
        "outputId": "970fd9bc-c728-4036-b107-ff578b578e8f"
      },
      "outputs": [],
      "source": [
        "import numpy as np # importing the numpy library\n",
        "\n",
        "# initializing a plot\n",
        "fig, axes = plt.subplots(2, 5, figsize=(14, 6)) # initializing a plot with 2 rows and 5 columns with a figure size of 14x6\n",
        "axes = axes.ravel() # flattening the axes array to make it easier to iterate over \n",
        "\n",
        "# plotting one image from each class\n",
        "for i in range(10): # iterating over the 10 classes in the CIFAR-10 dataset\n",
        "    # finding the index of the first image of each class\n",
        "    index = np.where(train_labels.flatten() == i)[0][0] # finding the index of the first image of each class in the train_labels array\n",
        "    img = train_images[index] # getting the image at the index found above \n",
        "\n",
        "    # plottng the image\n",
        "    axes[i].imshow(img, cmap=plt.cm.binary) # plotting the image with a binary colormap\n",
        "    axes[i].set_title(class_names[i]) # setting the title of the image to the class name\n",
        "    axes[i].axis('off') # turning off the axis for the image\n",
        "\n",
        "plt.tight_layout() # adjusting the layout of the plot\n",
        "plt.show() # displaying the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZRJEHrFc3YE"
      },
      "outputs": [],
      "source": [
        "# converting labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels) # converting the train_labels to one-hot encoding so that they can be used in the model, since the model expects the labels to be in one-hot encoding\n",
        "test_labels = to_categorical(test_labels) # converting the test_labels to one-hot encoding so that they can be used in the model, since the model expects the labels to be in one-hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xxypz1fHuHn"
      },
      "source": [
        "**Model building**\n",
        "\n",
        "Build a convnet without adding data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F842KibeHw7d",
        "outputId": "c25dd879-a6f2-4a5e-ff57-1b2af002f970"
      },
      "outputs": [],
      "source": [
        "# Input layer\n",
        "inputs = tf.keras.Input(shape=(32, 32, 3)) # creating an input layer with a shape of 32x32x3 (32x32 pixels with 3 color channels) \n",
        "\n",
        "# Normalization layer\n",
        "x = layers.Rescaling(1./255)(inputs) # normalizing the input data by dividing by 255 to scale the pixel values to the range [0, 1] \n",
        "\n",
        "# First Convolutional Block\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(x) # creating a convolutional layer with 32 filters of size 3x3 and ReLU activation function \n",
        "x = layers.MaxPooling2D((2, 2))(x) # creating a max pooling layer with a pool size of 2x2 \n",
        "\n",
        "# Second Convolutional Block\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x) # creating a convolutional layer with 64 filters of size 3x3 and ReLU activation function\n",
        "x = layers.MaxPooling2D((2, 2))(x) # creating a max pooling layer with a pool size of 2x2\n",
        "\n",
        "# Third Convolutional Block\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x) # creating a convolutional layer with 128 filters of size 3x3 and ReLU activation function\n",
        "x = layers.MaxPooling2D((2, 2))(x) # creating a max pooling layer with a pool size of 2x2\n",
        "\n",
        "# Flatten and Dense Layers\n",
        "x = layers.Flatten()(x) # flattening the output of the convolutional layers\n",
        "x = layers.Dense(64, activation='relu')(x) # creating a dense layer with 64 units and ReLU activation function\n",
        "outputs = layers.Dense(10, activation='softmax')(x) # creating a dense layer with 10 units (one for each class) and softmax activation function\n",
        "\n",
        "# Model creation\n",
        "model = models.Model(inputs=inputs, outputs=outputs) # creating a model with the input and output layers\n",
        "\n",
        "model.summary() # printing a summary of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwCLbp6VIDhz"
      },
      "source": [
        "**Compile and train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TAhJyTaIH29",
        "outputId": "d9cebb39-08a5-454c-a0e1-b5a09b4b4968"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']) # compiling the model with the Adam optimizer, categorical crossentropy loss function, and accuracy metric \n",
        "\n",
        "callbacks = [ # creating a list of callbacks to be used during training\n",
        "    keras.callbacks.ModelCheckpoint( # creating a ModelCheckpoint callback to save the best model during training\n",
        "        filepath=\"convnet_from_scratch.keras\", # specifying the file path to save the model\n",
        "        save_best_only=True, # saving only the best model\n",
        "        monitor=\"val_loss\") # monitoring the validation loss to determine the best model\n",
        "]\n",
        "\n",
        "history = model.fit(train_images, train_labels, # training the model on the training data\n",
        "                    epochs=50, # training for 50 epochs\n",
        "                    validation_split=0.2, # using 20% of the training data for validation\n",
        "                    batch_size=256, # using a batch size of 256 (this is the number of samples used in each iteration of training)\n",
        "                    callbacks = callbacks) # using the callbacks defined above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAxbRR0dIUNk"
      },
      "source": [
        "**Plotting Training and Validation Loss and Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "3kjmA3y2Ma0r",
        "outputId": "f4866a52-a29e-4cb6-e0eb-d83238010586"
      },
      "outputs": [],
      "source": [
        "# assuming 'history' is the return value from model.fit()\n",
        "history_dict = history.history # extracting the history dictionary from the history object\n",
        "\n",
        "# extracting loss and accuracy history\n",
        "train_loss = history_dict['loss'] # extracting the training loss history\n",
        "val_loss = history_dict['val_loss'] # extracting the validation loss history\n",
        "train_accuracy = history_dict['accuracy'] # extracting the training accuracy history\n",
        "val_accuracy = history_dict['val_accuracy'] # extracting the validation accuracy history\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1) # creating a range of epochs for plotting \n",
        "\n",
        "# plotting training and validation loss\n",
        "plt.figure(figsize=(14, 5)) # setting the figure size for the plot to 14x5 \n",
        "\n",
        "# training and validation loss plot\n",
        "plt.subplot(1, 2, 1) # creating a subplot with 1 row and 2 columns and selecting the first plot\n",
        "plt.plot(epochs, train_loss, 'bo-', label='Training Loss') # plotting the training loss\n",
        "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss') # plotting the validation loss\n",
        "plt.title('Training and Validation Loss') # setting the title of the plot\n",
        "plt.xlabel('Epochs') # setting the x-axis label\n",
        "plt.ylabel('Loss') # setting the y-axis label\n",
        "plt.legend() # displaying the legend\n",
        "\n",
        "# training and validation accuracy plot\n",
        "plt.subplot(1, 2, 2) # selecting the second plot\n",
        "plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy') # plotting the training accuracy\n",
        "plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy') # plotting the validation accuracy\n",
        "plt.title('Training and Validation Accuracy') # setting the title of the plot\n",
        "plt.xlabel('Epochs') # setting the x-axis label\n",
        "plt.ylabel('Accuracy') # setting the y-axis label\n",
        "plt.legend() # displaying the legend\n",
        "\n",
        "# adjusting the plots to ensure they don't overlap\n",
        "plt.tight_layout() # adjusting the layout of the plot\n",
        "plt.show() # displaying the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgH9frSGINrV"
      },
      "source": [
        "**Test data evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaCGk0QtIM98",
        "outputId": "2f120777-7751-48e2-fa03-c251a20cae8a"
      },
      "outputs": [],
      "source": [
        "best_model = keras.models.load_model(\"convnet_from_scratch.keras\") # loading the best model saved during training\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels) # evaluating the best model on the test data\n",
        "print(f\"Test accuracy: {test_acc}\") # printing the test accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2S3a8cBNjIs"
      },
      "source": [
        "## Data augmentation addition\n",
        "\n",
        "Now, add a data augmentation step and compare model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVDLB10hN6O_"
      },
      "source": [
        "**Model building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFquM93qNziR",
        "outputId": "fc3ab853-89ea-4e53-fbd4-abef8f2b9168"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential( # creating a sequential model for data augmentation\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"), # randomly flipping the image horizontally \n",
        "        layers.RandomRotation(0.1), # randomly rotating the image by a factor of 0.1\n",
        "        layers.RandomZoom(0.2), # randomly zooming into the image by a factor of 0.2\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3)) # creating an input layer with a shape of 32x32x3\n",
        "\n",
        "# applying augmentation on the inputs\n",
        "x = data_augmentation(inputs) # applying the data augmentation on the input data\n",
        "\n",
        "# Normalization layer\n",
        "x = layers.Rescaling(1./255)(x) # normalizing the input data by dividing by 255 to scale the pixel values to the range [0, 1]\n",
        "\n",
        "# Convolutional blocks and rest of the model\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(x) # creating a convolutional layer with 32 filters of size 3x3 and ReLU activation function\n",
        "x = layers.MaxPooling2D((2, 2))(x) # creating a max pooling layer with a pool size of 2x2\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x) # creating a convolutional layer with 64 filters of size 3x3 and ReLU activation function\n",
        "x = layers.MaxPooling2D((2, 2))(x) # creating a max pooling layer with a pool size of 2x2\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x) # creating a convolutional layer with 128 filters of size 3x3 and ReLU activation function\n",
        "x = layers.MaxPooling2D((2, 2))(x) # creating a max pooling layer with a pool size of 2x2\n",
        "x = layers.Flatten()(x) # flattening the output of the convolutional layers\n",
        "x = layers.Dense(64, activation='relu')(x) # creating a dense layer with 64 units and ReLU activation function\n",
        "outputs = layers.Dense(10, activation='softmax')(x) # creating a dense layer with 10 units (one for each class) and softmax activation function\n",
        "\n",
        "# creating the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs) # creating a model with the input and output layers\n",
        "\n",
        "model.summary() # printing a summary of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eryLdqjOKZh"
      },
      "source": [
        "**Compile and train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2NTPCulOPva"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', # compiling the model with the Adam optimizer\n",
        "              loss='categorical_crossentropy', # using the categorical crossentropy loss function\n",
        "              metrics=['accuracy']) # using the accuracy metric\n",
        "\n",
        "callbacks = [ # creating a list of callbacks to be used during training\n",
        "    keras.callbacks.ModelCheckpoint( # creating a ModelCheckpoint callback to save the best model during training\n",
        "        filepath=\"aug_convnet_from_scratch.keras\", # specifying the file path to save the model\n",
        "        save_best_only=True, # saving only the best model\n",
        "        monitor=\"val_loss\") # monitoring the validation loss to determine the best model\n",
        "]\n",
        "\n",
        "history = model.fit(train_images, train_labels, # training the model on the training data\n",
        "                    epochs=100, # training for 100 epochs\n",
        "                    validation_split=0.2, # using 20% of the training data for validation\n",
        "                    batch_size=256, # using a batch size of 256 (this is the number of samples used in each iteration of training)\n",
        "                    callbacks = callbacks, # using the callbacks defined above\n",
        "                    verbose=0) # setting the verbosity to 0 to suppress the output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WaJvpEMObkn"
      },
      "source": [
        "**Plotting Training and Validation Loss and Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "b-GXrsvKOWNb",
        "outputId": "2894dc3f-9ec3-495e-b872-ca6d53b71f94"
      },
      "outputs": [],
      "source": [
        "# assuming 'history' is the return value from model.fit()\n",
        "history_dict = history.history # extracting the history dictionary from the history object\n",
        "\n",
        "# extracting loss and accuracy history \n",
        "train_loss = history_dict['loss'] # extracting the training loss history\n",
        "val_loss = history_dict['val_loss'] # extracting the validation loss history\n",
        "train_accuracy = history_dict['accuracy'] # extracting the training accuracy history\n",
        "val_accuracy = history_dict['val_accuracy'] # extracting the validation accuracy history\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1) # creating a range of epochs for plotting\n",
        "\n",
        "# plotting training and validation loss\n",
        "plt.figure(figsize=(14, 5)) # setting the figure size for the plot to 14x5\n",
        "\n",
        "# training and validation loss plot\n",
        "plt.subplot(1, 2, 1) # creating a subplot with 1 row and 2 columns and selecting the first plot\n",
        "plt.plot(epochs, train_loss, 'bo-', label='Training Loss') # plotting the training loss\n",
        "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss') # plotting the validation loss\n",
        "plt.title('Training and Validation Loss') # setting the title of the plot\n",
        "plt.xlabel('Epochs') # setting the x-axis label\n",
        "plt.ylabel('Loss') # setting the y-axis label\n",
        "plt.legend() # displaying the legend\n",
        "\n",
        "# training and validation accuracy plot\n",
        "plt.subplot(1, 2, 2) # selecting the second plot\n",
        "plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy') # plotting the training accuracy\n",
        "plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy') # plotting the validation accuracy\n",
        "plt.title('Training and Validation Accuracy') # setting the title of the plot\n",
        "plt.xlabel('Epochs') # setting the x-axis label\n",
        "plt.ylabel('Accuracy') # setting the y-axis label\n",
        "plt.legend() # displaying the legend\n",
        "\n",
        "# adjusting the plots to ensure they don't overlap\n",
        "plt.tight_layout() # adjusting the layout of the plot\n",
        "plt.show() # displaying the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt2M2D9fgWy6"
      },
      "outputs": [],
      "source": [
        "def print_best_val_loss_and_accuracy(history): # defining a function to print the best validation loss and accuracy\n",
        "    history_dict = history.history # extracting the history dictionary from the history object\n",
        "\n",
        "    # finding the index of the best validation loss\n",
        "    best_val_loss_index = np.argmin(history_dict['val_loss']) # finding the index of the minimum validation loss in the history dictionary by accessing the 'val_loss' key\n",
        "\n",
        "    # retrieving the best validation loss\n",
        "    best_val_loss = history_dict['val_loss'][best_val_loss_index] # retrieving the best validation loss based on the index found above by accessing the 'val_loss' key in the history dictionary\n",
        "\n",
        "    # retrieving the validation accuracy corresponding to the best validation loss\n",
        "    best_val_accuracy = history_dict['val_accuracy'][best_val_loss_index] # retrieving the validation accuracy corresponding to the best validation loss based on the index found above by accessing the 'val_accuracy' key in the history dictionary\n",
        "\n",
        "    print(f\"Best Validation Loss: {best_val_loss}\") # printing the best validation loss\n",
        "    print(f\"Validation Accuracy at Best Loss: {best_val_accuracy}\") # printing the validation accuracy at the best loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CahEbDi6iBgw",
        "outputId": "0c1dc1f0-6cc7-420a-a275-402564902beb"
      },
      "outputs": [],
      "source": [
        "print_best_val_loss_and_accuracy(history) # calling the function to print the best validation loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uusqRVX0aXtS",
        "outputId": "8b94d157-555e-4766-d7f1-f6be0004307e"
      },
      "outputs": [],
      "source": [
        "best_model = keras.models.load_model(\"aug_convnet_from_scratch.keras\") # loading the best model saved during training\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels) # evaluating the best model on the test data\n",
        "print(f\"Test accuracy: {test_acc}\") # printing the test accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR5rWCudhepV"
      },
      "source": [
        "## Experiment with more data augmentation\n",
        "Try experimenting with adding more data augmentation techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaPuoBv_hjqn"
      },
      "outputs": [],
      "source": [
        "# Enhanced data augmentation\n",
        "data_augmentation = keras.Sequential( # creating a sequential model for data augmentation\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\", input_shape=(32, 32, 3)), # flipping the image horizontally \n",
        "        layers.RandomRotation(0.1), # rotating the image by a factor of 0.1\n",
        "        layers.RandomZoom(0.2), # zooming into the image by a factor of 0.2\n",
        "        layers.RandomContrast(0.1), # adjusting the contrast of the image by a factor of 0.1\n",
        "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1), # translating the image by a factor of 0.1\n",
        "        # potentially add more augmentation techniques here\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3)) # creating an input layer with a shape of 32x32x3\n",
        "\n",
        "# applying enhanced augmentation on the inputs\n",
        "x = data_augmentation(inputs) # applying the data augmentation on the input data\n",
        "\n",
        "# continuing with normalization and the rest of your model\n",
        "x = layers.Rescaling(1./255)(x) # normalizing the input data by dividing by 255 to scale the pixel values to the range [0, 1]\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(x) # creating a convolutional layer with 32 filters of size 3x3 and ReLU activation function\n",
        "x = layers.MaxPooling2D((2, 2))(x) # creating a max pooling layer with a pool size of 2x2\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x) # creating a convolutional layer with 64 filters of size 3x3 and ReLU activation function\n",
        "x = layers.MaxPooling2D((2, 2))(x) # creating a max pooling layer with a pool size of 2x2\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x) # creating a convolutional layer with 128 filters of size 3x3 and ReLU activation function\n",
        "x = layers.MaxPooling2D((2, 2))(x) # creating a max pooling layer with a pool size of 2x2\n",
        "x = layers.Flatten()(x) # flattening the output of the convolutional layers\n",
        "x = layers.Dense(64, activation='relu')(x) # creating a dense layer with 64 units and ReLU activation function\n",
        "outputs = layers.Dense(10, activation='softmax')(x) # creating a dense layer with 10 units (one for each class) and softmax activation function\n",
        "\n",
        "# creating the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs) # creating a model with the input and output layers "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwKsaaQThvbi",
        "outputId": "6a5070d9-ad5e-46ba-af88-43ea895ca6bc"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', # compiling the model with the Adam optimizer\n",
        "              loss='categorical_crossentropy', # using the categorical crossentropy loss function\n",
        "              metrics=['accuracy']) # using the accuracy metric\n",
        "\n",
        "callbacks = [ # creating a list of callbacks to be used during training\n",
        "    keras.callbacks.ModelCheckpoint( # creating a ModelCheckpoint callback to save the best model during training\n",
        "        filepath=\"more_aug_convnet_from_scratch.keras\", # specifying the file path to save the model\n",
        "        save_best_only=True, # saving only the best model\n",
        "        monitor=\"val_loss\") # monitoring the validation loss to determine the best model\n",
        "]\n",
        "\n",
        "history = model.fit(train_images, train_labels, # training the model on the training data\n",
        "                    epochs=100, # training for 100 epochs\n",
        "                    validation_split=0.2, # using 20% of the training data for validation\n",
        "                    batch_size=256, # using a batch size of 256 (this is the number of samples used in each iteration of training)\n",
        "                    callbacks = callbacks) # using the callbacks defined above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "mtCN_PgTiIaF",
        "outputId": "040e6c7d-8850-4c82-b82a-a89c78583b6d"
      },
      "outputs": [],
      "source": [
        "# assuming 'history' is the return value from model.fit()\n",
        "history_dict = history.history # extracting the history dictionary from the history object\n",
        "\n",
        "# extracting loss and accuracy history\n",
        "train_loss = history_dict['loss'] # extracting the training loss history\n",
        "val_loss = history_dict['val_loss'] # extracting the validation loss history\n",
        "train_accuracy = history_dict['accuracy'] # extracting the training accuracy history\n",
        "val_accuracy = history_dict['val_accuracy'] # extracting the validation accuracy history\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1) # creating a range of epochs for plotting\n",
        " \n",
        "# plotting training and validation loss\n",
        "plt.figure(figsize=(14, 5)) # setting the figure size for the plot to 14x5\n",
        "\n",
        "# training and validation loss plot\n",
        "plt.subplot(1, 2, 1) # creating a subplot with 1 row and 2 columns and selecting the first plot\n",
        "plt.plot(epochs, train_loss, 'bo-', label='Training Loss') # plotting the training loss\n",
        "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss') # plotting the validation loss\n",
        "plt.title('Training and Validation Loss') # setting the title of the plot\n",
        "plt.xlabel('Epochs') # setting the x-axis label\n",
        "plt.ylabel('Loss') # setting the y-axis label\n",
        "plt.legend() # displaying the legend\n",
        "\n",
        "# training and validation accuracy plot\n",
        "plt.subplot(1, 2, 2) # selecting the second plot\n",
        "plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy') # plotting the training accuracy\n",
        "plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy') # plotting the validation accuracy\n",
        "plt.title('Training and Validation Accuracy') # setting the title of the plot\n",
        "plt.xlabel('Epochs') # setting the x-axis label\n",
        "plt.ylabel('Accuracy') # setting the y-axis label\n",
        "plt.legend() # displaying the legend\n",
        "\n",
        "plt.tight_layout() # adjusting the layout of the plot to prevent overlap\n",
        "plt.show() # displaying the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-BZW2AQiMYa",
        "outputId": "c9a63351-863a-4045-9526-58b319c2293f"
      },
      "outputs": [],
      "source": [
        "print_best_val_loss_and_accuracy(history) # calling the function to print the best validation loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdszpo7qiO8U",
        "outputId": "6c2428a0-d421-4303-ecd8-9dacd455fb17"
      },
      "outputs": [],
      "source": [
        "best_model = keras.models.load_model(\"more_aug_convnet_from_scratch.keras\") # loading the best model saved during training\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels) # evaluating the best model on the test data\n",
        "print(f\"Test accuracy: {test_acc}\") # printing the test accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_v1Mj_enxmZ"
      },
      "source": [
        "## What's next?\n",
        "\n",
        "To further increase the performance of our model, we could make some tweaks here and there, like icreasing the number of filters in the convolutional layers can help the model learn more complex features. Similarly, adjusting the number of neurons in the dense layers might improve learning capacity.\n",
        "\n",
        "However, at this stage, gains from such changes are likely going to marginal.\n",
        "\n",
        "Instead, there are two things that would likely boost performance:\n",
        "\n",
        "1) More and better data! The data is greatly pixilated. Higher resolution data would allow us to build deeper models that generalize better.\n",
        "\n",
        "2) More and better tricks! Next in the course, we'll learn about advanced computer vision techniques that can push performance even further."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
