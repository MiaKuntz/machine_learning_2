{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGWP57UC6tZy"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pahya5p6tZz"
      },
      "source": [
        "# Advanced deep learning for computer vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syy-eG4M6tZ0"
      },
      "source": [
        "## Three essential computer vision tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7FAI22I6tZ0"
      },
      "source": [
        "## An image segmentation example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zHWZ7Wo6tZ0"
      },
      "outputs": [],
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz # downloading the dataset from the given link \n",
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz # downloading the dataset from the given link\n",
        "!tar -xf images.tar.gz # extracting the images from the tar file\n",
        "!tar -xf annotations.tar.gz # extracting the annotations from the tar file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oNBL4II6tZ0"
      },
      "outputs": [],
      "source": [
        "import os # importing os module to interact with the file system \n",
        "\n",
        "input_dir = \"images/\" # specifying input directory where the images are stored\n",
        "target_dir = \"annotations/trimaps/\" # specifying target directory where the annotations are stored\n",
        "\n",
        "input_img_paths = sorted( # sorting the images in the input directory\n",
        "    [os.path.join(input_dir, fname) # joining the input directory with the file name\n",
        "     for fname in os.listdir(input_dir) # listing the files in the input directory\n",
        "     if fname.endswith(\".jpg\")]) # checking if the file is of jpg format\n",
        "target_paths = sorted( # sorting the annotations in the target directory\n",
        "    [os.path.join(target_dir, fname) # joining the target directory with the file name\n",
        "     for fname in os.listdir(target_dir) # listing the files in the target directory\n",
        "     if fname.endswith(\".png\") and not fname.startswith(\".\")]) # checking if the file is of png format and not starting with a dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUGKsOvH6tZ1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt # importing matplotlib to plot the images\n",
        "from tensorflow.keras.utils import load_img, img_to_array # importing load_img and img_to_array from tensorflow.keras.utils\n",
        "\n",
        "plt.axis(\"off\") # turning off the axis\n",
        "plt.imshow(load_img(input_img_paths[9])) # loading the image from the input directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtfIVhgR6tZ1"
      },
      "outputs": [],
      "source": [
        "def display_target(target_array): # defining a function to display the target array\n",
        "    normalized_array = (target_array.astype(\"uint8\") - 1) * 127 # normalizing the array values by subtracting 1 and multiplying by 127 which is the maximum value of the array \n",
        "    plt.axis(\"off\") # turning off the axis\n",
        "    plt.imshow(normalized_array[:, :, 0]) # displaying the image\n",
        "\n",
        "img = img_to_array(load_img(target_paths[9], color_mode=\"grayscale\")) # loading the image from the target directory and converting it to an array\n",
        "display_target(img) # displaying the target array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeu0mr0q6tZ1"
      },
      "outputs": [],
      "source": [
        "import numpy as np # importing numpy module\n",
        "import random # importing random module\n",
        "\n",
        "img_size = (200, 200) # specifying the image size\n",
        "num_imgs = len(input_img_paths) # getting the number of images\n",
        "\n",
        "random.Random(1337).shuffle(input_img_paths) # shuffling the input image paths\n",
        "random.Random(1337).shuffle(target_paths) # shuffling the target paths\n",
        "\n",
        "def path_to_input_image(path): # defining a function to convert the path to input image\n",
        "    return img_to_array(load_img(path, target_size=img_size)) # loading the image from the path and converting it to an array\n",
        "\n",
        "def path_to_target(path): # defining a function to convert the path to target\n",
        "    img = img_to_array( # converting the image to an array\n",
        "        load_img(path, target_size=img_size, color_mode=\"grayscale\")) # loading the image from the path and converting it to an array\n",
        "    img = img.astype(\"uint8\") - 1 # converting the array to unsigned integer and subtracting 1\n",
        "    return img # returning the image\n",
        "\n",
        "input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\") # creating an array of zeros with the specified shape\n",
        "targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\") # creating an array of zeros with the specified shape\n",
        "for i in range(num_imgs): # iterating through the number of images\n",
        "    input_imgs[i] = path_to_input_image(input_img_paths[i]) # converting the input image path to an image\n",
        "    targets[i] = path_to_target(target_paths[i]) # converting the target path to an image \n",
        "\n",
        "num_val_samples = 1000 # specifying the number of validation samples\n",
        "train_input_imgs = input_imgs[:-num_val_samples] # getting the training input images\n",
        "train_targets = targets[:-num_val_samples] # getting the training targets\n",
        "val_input_imgs = input_imgs[-num_val_samples:] # getting the validation input images\n",
        "val_targets = targets[-num_val_samples:] # getting the validation targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fewuYax56tZ1"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras # importing keras from tensorflow\n",
        "from tensorflow.keras import layers # importing layers from tensorflow.keras\n",
        "\n",
        "def get_model(img_size, num_classes): # defining a function to get the model\n",
        "    inputs = keras.Input(shape=img_size + (3,)) # specifying the input shape\n",
        "    x = layers.Rescaling(1./255)(inputs) # rescaling the input\n",
        "\n",
        "    x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x) # adding a convolutional layer\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x) # adding a convolutional layer\n",
        "    x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "    x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "\n",
        "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x) # adding a convolutional layer based on the input parameters previously defined\n",
        "\n",
        "    model = keras.Model(inputs, outputs) # creating the model\n",
        "    return model # returning the model\n",
        "\n",
        "model = get_model(img_size=img_size, num_classes=3) # getting the model and specifying the image size and number of classes as 3 (the number of classes in the dataset, which are cat, dog and background)\n",
        "model.summary() # displaying the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZgH8dgu6tZ2"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\") # compiling the model\n",
        "\n",
        "callbacks = [ # specifying the callbacks for the model\n",
        "    keras.callbacks.ModelCheckpoint(\"oxford_segmentation.keras\", # specifying the model checkpoint \n",
        "                                    save_best_only=True) # saving the best model\n",
        "]\n",
        "\n",
        "history = model.fit(train_input_imgs, train_targets, # fitting the model\n",
        "                    epochs=50, # specifying the number of epochs\n",
        "                    callbacks=callbacks, # specifying the callbacks\n",
        "                    batch_size=64, # specifying the batch size\n",
        "                    validation_data=(val_input_imgs, val_targets)) # specifying the validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix9JYb5k6tZ2"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(history.history[\"loss\"]) + 1) # specifying the epochs\n",
        "loss = history.history[\"loss\"] # getting the loss\n",
        "val_loss = history.history[\"val_loss\"] # getting the validation loss\n",
        "plt.figure() # creating a figure\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\") # plotting the training loss\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\") # plotting the validation loss\n",
        "plt.title(\"Training and validation loss\") # specifying the title\n",
        "plt.legend() # adding the legend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6BG5-ny6tZ2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import array_to_img # importing array_to_img from tensorflow.keras.utils\n",
        "\n",
        "model = keras.models.load_model(\"oxford_segmentation.keras\") # loading the model\n",
        "\n",
        "i = 4 # specifying the index\n",
        "test_image = val_input_imgs[i] # getting the test image\n",
        "plt.axis(\"off\") # turning off the axis\n",
        "plt.imshow(array_to_img(test_image)) # displaying the image\n",
        "\n",
        "mask = model.predict(np.expand_dims(test_image, 0))[0] # predicting the mask\n",
        "\n",
        "def display_mask(pred): # defining a function to display the mask\n",
        "    mask = np.argmax(pred, axis=-1) # getting the argmax of the prediction\n",
        "    mask *= 127 # multiplying the mask by 127\n",
        "    plt.axis(\"off\") # turning off the axis\n",
        "    plt.imshow(mask) # displaying the mask\n",
        "\n",
        "display_mask(mask) # displaying the mask"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter09_part01_image-segmentation.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
