{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lLFqQLEbmsq"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUZcU5Pzbmsq"
      },
      "source": [
        "## DeepDream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_f8PZ6Ubmsr"
      },
      "source": [
        "### Implementing DeepDream in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-BVNgMBbmsr"
      },
      "source": [
        "**Fetching the test image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGifk1czbmsr"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras # importing keras from tensorflow\n",
        "import matplotlib.pyplot as plt # importing matplotlib.pyplot as plt\n",
        "\n",
        "base_image_path = keras.utils.get_file( # getting the image from the url\n",
        "    \"coast.jpg\", origin=\"https://img-datasets.s3.amazonaws.com/coast.jpg\") # url of the image\n",
        "\n",
        "plt.axis(\"off\") # turning off the axis\n",
        "plt.imshow(keras.utils.load_img(base_image_path)) # loading the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EUAOd38bmss"
      },
      "source": [
        "**Instantiating a pretrained `InceptionV3` model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC8RbOi1bmss"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import inception_v3 # importing inception_v3 from tensorflow.keras.applications\n",
        "model = inception_v3.InceptionV3(weights=\"imagenet\", include_top=False) # loading the inception_v3 model with imagenet weights and without the top layer of the model (classification layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNCLU6YMbmss"
      },
      "source": [
        "**Configuring the contribution of each layer to the DeepDream loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw3K64agbmst"
      },
      "outputs": [],
      "source": [
        "layer_settings = { # defining the layer settings\n",
        "    \"mixed4\": 1.0, # mixed4 layer with 1.0\n",
        "    \"mixed5\": 1.5, # mixed5 layer with 1.5\n",
        "    \"mixed6\": 2.0, # mixed6 layer with 2.0\n",
        "    \"mixed7\": 2.5, # mixed7 layer with 2.5\n",
        "}\n",
        "outputs_dict = dict( # defining the outputs_dict\n",
        "    [\n",
        "        (layer.name, layer.output) # getting the output of the layer\n",
        "        for layer in [model.get_layer(name) for name in layer_settings.keys()] # getting the output of the layer for the layer in the model with the name in the layer_settings\n",
        "    ]\n",
        ")\n",
        "feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict) # defining the feature_extractor model with the inputs and outputs_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVTPiiQXbmst"
      },
      "source": [
        "**The DeepDream loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoubPtZUbmst"
      },
      "outputs": [],
      "source": [
        "def compute_loss(input_image): # defining the compute_loss function with the input_image\n",
        "    features = feature_extractor(input_image) # extracting the features from the input_image\n",
        "    loss = tf.zeros(shape=()) # defining the loss as a tensor with shape ()\n",
        "    for name in features.keys(): # iterating through the names in the features\n",
        "        coeff = layer_settings[name] # getting the coefficient from the layer_settings\n",
        "        activation = features[name] # getting the activation from the features\n",
        "        loss += coeff * tf.reduce_mean(tf.square(activation[:, 2:-2, 2:-2, :])) # adding the coefficient multiplied by the mean of the square of the activation to the loss\n",
        "    return loss # returning the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akp3CxZEbmst"
      },
      "source": [
        "**The DeepDream gradient ascent process**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0ErDL-Sbmst"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # importing tensorflow as tf\n",
        "\n",
        "@tf.function # defining the function as a tensorflow function\n",
        "def gradient_ascent_step(image, learning_rate): # defining the gradient_ascent_step function with the image and learning_rate\n",
        "    with tf.GradientTape() as tape: # defining the tape\n",
        "        tape.watch(image) # watching the image\n",
        "        loss = compute_loss(image) # computing the loss\n",
        "    grads = tape.gradient(loss, image) # getting the gradients\n",
        "    grads = tf.math.l2_normalize(grads) # normalizing the gradients\n",
        "    image += learning_rate * grads # adding the learning_rate multiplied by the gradients to the image\n",
        "    return loss, image # returning the loss and image\n",
        "\n",
        "\n",
        "def gradient_ascent_loop(image, iterations, learning_rate, max_loss=None): # defining the gradient_ascent_loop function with the image, iterations, learning_rate, and max_loss\n",
        "    for i in range(iterations): # iterating through the range of iterations\n",
        "        loss, image = gradient_ascent_step(image, learning_rate) # getting the loss and image from the gradient_ascent_step function\n",
        "        if max_loss is not None and loss > max_loss: # if the max_loss is not None and the loss is greater than the max_loss\n",
        "            break # break the loop\n",
        "        print(f\"... Loss value at step {i}: {loss:.2f}\") # print the loss value at step i\n",
        "    return image # return the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRUsWMbwbmsu"
      },
      "outputs": [],
      "source": [
        "# defining the gradient ascent parameters\n",
        "step = 20. # step is 20\n",
        "num_octave = 3 # num_octave is 3\n",
        "octave_scale = 1.4 # octave_scale is 1.4\n",
        "iterations = 30 # iterations is 30\n",
        "max_loss = 15. # max_loss is 15."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3PebiMFbmsu"
      },
      "source": [
        "**Image processing utilities**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMatm14wbmsu"
      },
      "outputs": [],
      "source": [
        "import numpy as np # importing numpy as np\n",
        "\n",
        "def preprocess_image(image_path): # defining the preprocess_image function with the image_path\n",
        "    img = keras.utils.load_img(image_path) # loading the image\n",
        "    img = keras.utils.img_to_array(img) # converting the image to an array\n",
        "    img = np.expand_dims(img, axis=0) # expanding the dimensions of the image\n",
        "    img = keras.applications.inception_v3.preprocess_input(img) # preprocessing the image\n",
        "    return img # returning the image\n",
        "\n",
        "def deprocess_image(img): # defining the deprocess_image function with the img\n",
        "    img = img.reshape((img.shape[1], img.shape[2], 3)) # reshaping the image\n",
        "    img /= 2.0 # dividing the image by 2.0\n",
        "    img += 0.5 # adding 0.5 to the image\n",
        "    img *= 255. # multiplying the image by 255.\n",
        "    img = np.clip(img, 0, 255).astype(\"uint8\") # clipping the image and converting it to an unsigned integer\n",
        "    return img # returning the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4miRiXv7bmsu"
      },
      "source": [
        "**Running gradient ascent over multiple successive \"octaves\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P25L3dxVbmsu"
      },
      "outputs": [],
      "source": [
        "original_img = preprocess_image(base_image_path) # preprocessing the original image\n",
        "original_shape = original_img.shape[1:3] # getting the original shape of the image\n",
        "\n",
        "successive_shapes = [original_shape] # defining the successive_shapes with the original_shape\n",
        "for i in range(1, num_octave): # iterating through the range of 1 to num_octave\n",
        "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape]) # getting the shape of the image\n",
        "    successive_shapes.append(shape) # appending the shape to the successive_shapes\n",
        "successive_shapes = successive_shapes[::-1] # reversing the successive_shapes\n",
        "\n",
        "shrunk_original_img = tf.image.resize(original_img, successive_shapes[0]) # resizing the original image\n",
        "\n",
        "img = tf.identity(original_img) # getting the identity of the original image\n",
        "for i, shape in enumerate(successive_shapes): # iterating through the enumerate of the successive_shapes\n",
        "    print(f\"Processing octave {i} with shape {shape}\") # printing the octave and shape \n",
        "    img = tf.image.resize(img, shape) # resizing the image\n",
        "    img = gradient_ascent_loop( # getting the image from the gradient_ascent_loop function\n",
        "        img, iterations=iterations, learning_rate=step, max_loss=max_loss # with the iterations, learning_rate, and max_loss\n",
        "    )\n",
        "    upscaled_shrunk_original_img = tf.image.resize(shrunk_original_img, shape) # resizing the shrunk original image\n",
        "    same_size_original = tf.image.resize(original_img, shape) # resizing the original image\n",
        "    lost_detail = same_size_original - upscaled_shrunk_original_img # getting the lost detail\n",
        "    img += lost_detail # adding the lost detail to the image\n",
        "    shrunk_original_img = tf.image.resize(original_img, shape) # resizing the original image\n",
        "\n",
        "keras.utils.save_img(\"dream.png\", deprocess_image(img.numpy())) # saving the image as dream.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNfn7bL5bmsu"
      },
      "source": [
        "### Wrapping up"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter12_part02_deep-dream.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
