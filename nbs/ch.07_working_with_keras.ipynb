{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHVrfbrHDnM8"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdGXnY2jDnM9"
      },
      "source": [
        "# Working with Keras: A deep dive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekbA_fuHDnM9"
      },
      "source": [
        "## A spectrum of workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eQD1NCRDnM9"
      },
      "source": [
        "## Different ways to build Keras models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqm71MMkDnM9"
      },
      "source": [
        "### The Sequential model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naWvrzCiDnM9"
      },
      "source": [
        "**The `Sequential` class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZapiCl8jDnM-"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras # importing keras from tensorflow package \n",
        "from tensorflow.keras import layers # importing layers from keras package\n",
        "\n",
        "model = keras.Sequential([ # defining the sequential model\n",
        "    layers.Dense(64, activation=\"relu\"), # adding a dense layer with 64 neurons and relu activation function\n",
        "    layers.Dense(10, activation=\"softmax\") # adding a dense layer with 10 neurons and softmax activation function\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgpRC18cDnM-"
      },
      "source": [
        "**Incrementally building a Sequential model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2J-yf3G-DnM_"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential() # defining the sequential model\n",
        "model.add(layers.Dense(64, activation=\"relu\")) # adding a dense layer with 64 neurons and relu activation function\n",
        "model.add(layers.Dense(10, activation=\"softmax\")) # adding a dense layer with 10 neurons and softmax activation function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVPOhFdpDnM_"
      },
      "source": [
        "**Calling a model for the first time to build it**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "73QtTrEeDnM_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(3, 64), dtype=float32, path=sequential_2/dense_4/kernel>,\n",
              " <KerasVariable shape=(64,), dtype=float32, path=sequential_2/dense_4/bias>,\n",
              " <KerasVariable shape=(64, 10), dtype=float32, path=sequential_2/dense_5/kernel>,\n",
              " <KerasVariable shape=(10,), dtype=float32, path=sequential_2/dense_5/bias>]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.build(input_shape=(None, 3)) # building the model with input shape of (None, 3) because we have 3 features in the input data \n",
        "model.weights # printing the weights of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAf8JksDDnM_"
      },
      "source": [
        "**The summary method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bWAocSlKDnM_"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary() # printing the summary of the model\n",
        "# The summary shows the number of parameters in each layer and the total number of parameters in the model\n",
        "# It also shows the output shape of each layer and the number of neurons in each layer\n",
        "# The output shape of the first layer is (None, 64) because the first layer has 64 neurons and the input shape is (None, 3)\n",
        "# The output shape of the second layer is (None, 10) because the second layer has 10 neurons and the input shape is (None, 64) which is the output shape of the first layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-VRxxQrDnM_"
      },
      "source": [
        "**Naming models and layers with the `name` argument**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t9sKS4JsDnM_"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_example_model\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"my_example_model\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ my_first_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ my_last_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ my_first_layer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ my_last_layer (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = keras.Sequential(name=\"my_example_model\") # defining the sequential model with a name \n",
        "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\")) # adding a dense layer with 64 neurons and relu activation function with a name \n",
        "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\")) # adding a dense layer with 10 neurons and softmax activation function with a name\n",
        "model.build((None, 3)) # building the model with input shape of (None, 3) because we have 3 features in the input data\n",
        "model.summary() # printing the summary of the model\n",
        "# The summary shows the number of parameters in each layer and the total number of parameters in the model with the names of the layers\n",
        "# It also shows the output shape of each layer and the number of neurons in each layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIf0-GGFDnM_"
      },
      "source": [
        "**Specifying the input shape of your model in advance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8yCDbhBiDnM_"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential() # defining the sequential model\n",
        "model.add(keras.Input(shape=(3,))) # adding an input layer with input shape of (None, 3) because we have 3 features in the input data\n",
        "model.add(layers.Dense(64, activation=\"relu\")) # adding a dense layer with 64 neurons and relu activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0HCXO5mSDnM_"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary() # printing the summary of the model\n",
        "# The summary shows the number of parameters in each layer and the total number of parameters in the model\n",
        "# It also shows the output shape of each layer and the number of neurons in each layer\n",
        "# The output shape of the first layer is (None, 64) because the first layer has 64 neurons and the input shape is (None, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tFolCvoLDnM_"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.add(layers.Dense(10, activation=\"softmax\")) # adding a dense layer with 10 neurons and softmax activation function \n",
        "model.summary() # printing the summary of the model\n",
        "# The summary shows the number of parameters in each layer and the total number of parameters in the model\n",
        "# It also shows the output shape of each layer and the number of neurons in each layer\n",
        "# The output shape of the second layer is (None, 10) because the second layer has 10 neurons and the input shape is (None, 64) which is the output shape of the first layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea-3aoNhDnNA"
      },
      "source": [
        "### The Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlxcQ2oTDnNA"
      },
      "source": [
        "#### A simple example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbyAy26PDnNA"
      },
      "source": [
        "**A simple Functional model with two `Dense` layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y71KXbxRDnNA"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(3,), name=\"my_input\") # defining the input layer with input shape of (None, 3) because we have 3 features in the input data\n",
        "features = layers.Dense(64, activation=\"relu\")(inputs) # adding a dense layer with 64 neurons and relu activation function\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features) # adding a dense layer with 10 neurons and softmax activation function\n",
        "model = keras.Model(inputs=inputs, outputs=outputs) # defining the model with the input and output layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X2J0SWxRDnNA"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(3,), name=\"my_input\") # defining the input layer with input shape of (None, 3) because we have 3 features in the input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CN7ms3U9DnNA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 3)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs.shape # printing the shape of the input layer\n",
        "# The shape of the input layer is (None, 3) because we have 3 features in the input data and the batch size is None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rwowPYV7DnNA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'float32'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs.dtype # printing the data type of the input layer\n",
        "# The data type of the input layer is float32 by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NVuoXa6VDnNA"
      },
      "outputs": [],
      "source": [
        "features = layers.Dense(64, activation=\"relu\")(inputs) # adding a dense layer with 64 neurons and relu activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8YuYIV7ADnNA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features.shape # printing the shape of the features layer\n",
        "# The shape of the features layer is (None, 64) because the dense layer has 64 neurons and the input shape is (None, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q-yomxDgDnNA"
      },
      "outputs": [],
      "source": [
        "outputs = layers.Dense(10, activation=\"softmax\")(features) # adding a dense layer with 10 neurons and softmax activation function\n",
        "model = keras.Model(inputs=inputs, outputs=outputs) # defining the model with the input and output layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AHHfgBWYDnNA"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ my_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ my_input (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary() # printing the summary of the model\n",
        "# The summary shows the number of parameters in each layer and the total number of parameters in the model\n",
        "# It also shows the output shape of each layer and the number of neurons in each layer\n",
        "# The output shape of the first layer is (None, 3) because the input shape is (None, 3) and the input layer has 3 features in the input data \n",
        "# The output shape of the second layer is (None, 64) because the dense layer has 64 neurons and the input shape is (None, 3) which is the output shape of the input layer\n",
        "# The output shape of the third layer is (None, 10) because the dense layer has 10 neurons and the input shape is (None, 64) which is the output shape of the dense layer\n",
        "# The total number of parameters in the model is 650 because the first dense layer has 64 neurons and 64*3=192 parameters and the second dense layer has 10 neurons and 10*64=640 parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f7uLt-oDnNA"
      },
      "source": [
        "#### Multi-input, multi-output models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpQL9szJDnNA"
      },
      "source": [
        "**A multi-input, multi-output Functional model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CBmHezNnDnNA"
      },
      "outputs": [],
      "source": [
        "vocabulary_size = 10000 # defining the vocabulary size \n",
        "num_tags = 100 # defining the number of tags\n",
        "num_departments = 4 # defining the number of departments\n",
        "\n",
        "title = keras.Input(shape=(vocabulary_size,), name=\"title\") # defining the input layer for the title with input shape of (None, vocabulary_size)\n",
        "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\") # defining the input layer for the text body with input shape of (None, vocabulary_size)\n",
        "tags = keras.Input(shape=(num_tags,), name=\"tags\") # defining the input layer for the tags with input shape of (None, num_tags)\n",
        "\n",
        "features = layers.Concatenate()([title, text_body, tags]) # concatenating the input layers because it needs to be combined before passing to the dense layer\n",
        "features = layers.Dense(64, activation=\"relu\")(features) # adding a dense layer with 64 neurons and relu activation function\n",
        "\n",
        "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features) # adding a dense layer with 1 neuron and sigmoid activation function for the priority\n",
        "department = layers.Dense( \n",
        "    num_departments, activation=\"softmax\", name=\"department\")(features) # adding a dense layer with num_departments neurons and softmax activation function for the department\n",
        "\n",
        "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department]) # defining the model with the input and output layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RngfFtJYDnNA"
      },
      "source": [
        "#### Training a multi-input, multi-output model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC0hLPzUDnNA"
      },
      "source": [
        "**Training a model by providing lists of input & target arrays**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rHspVYhqDnNA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - department_accuracy: 0.2140 - loss: 42.1553 - priority_mean_absolute_error: 0.4953\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - department_accuracy: 0.2349 - loss: 34.5862 - priority_mean_absolute_error: 0.4964\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # importing numpy package \n",
        "\n",
        "num_samples = 1280 # defining the number of samples\n",
        "\n",
        "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size)) # generating random title data\n",
        "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size)) # generating random text body data\n",
        "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags)) # generating random tags data\n",
        " \n",
        "priority_data = np.random.random(size=(num_samples, 1)) # generating random priority data\n",
        "department_data = np.random.randint(0, 2, size=(num_samples, num_departments)) # generating random department data\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with rmsprop optimizer\n",
        "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"], # defining the loss functions for the priority and department\n",
        "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]]) # defining the metrics for the priority and department\n",
        "model.fit([title_data, text_body_data, tags_data], # training the model with the input and output data\n",
        "          [priority_data, department_data], epochs=1) # training the model for 1 epoch with the input and output data \n",
        "model.evaluate([title_data, text_body_data, tags_data], # evaluating the model with the input and output data\n",
        "               [priority_data, department_data]) \n",
        "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data]) # predicting the priority and department with the input data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwf99dujDnNA"
      },
      "source": [
        "**Training a model by providing dicts of input & target arrays**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Vd2RJCGpDnNB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - department_accuracy: 0.2380 - loss: 42.4500 - priority_mean_absolute_error: 0.5078\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - department_accuracy: 0.5657 - loss: 49.6810 - priority_mean_absolute_error: 0.4964\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"rmsprop\", # compiling the model with rmsprop optimizer\n",
        "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"}, # defining the loss functions for the priority and department\n",
        "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]}) # defining the metrics for the priority and department\n",
        "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}, # training the model with the input and output data\n",
        "          {\"priority\": priority_data, \"department\": department_data}, \n",
        "          epochs=1) # training the model for 1 epoch\n",
        "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}, # evaluating the model with the input and output data\n",
        "               {\"priority\": priority_data, \"department\": department_data})\n",
        "priority_preds, department_preds = model.predict( # predicting the priority and department with the input data\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdM67DHlDnNB"
      },
      "source": [
        "#### The power of the Functional API: Access to layer connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gS4JfHfmDnNB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
          ]
        }
      ],
      "source": [
        "keras.utils.plot_model(model, \"ticket_classifier.png\") # plotting the model and saving it as ticket_classifier.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KKlP73vNDnNB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
          ]
        }
      ],
      "source": [
        "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True) # plotting the model with shape information and saving it as ticket_classifier_with_shape_info.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i6-fLMXDnNB"
      },
      "source": [
        "**Retrieving the inputs or outputs of a layer in a Functional model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "X_N3O_3-DnNB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<InputLayer name=title, built=True>,\n",
              " <InputLayer name=text_body, built=True>,\n",
              " <InputLayer name=tags, built=True>,\n",
              " <Concatenate name=concatenate, built=True>,\n",
              " <Dense name=dense_12, built=True>,\n",
              " <Dense name=priority, built=True>,\n",
              " <Dense name=department, built=True>]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers # printing the layers of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e_hw7-BzDnNB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasTensor shape=(None, 10000), dtype=float32, sparse=None, name=title>,\n",
              " <KerasTensor shape=(None, 10000), dtype=float32, sparse=None, name=text_body>,\n",
              " <KerasTensor shape=(None, 100), dtype=float32, sparse=None, name=tags>]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[3].input # printing the input of the 4th layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DkVPtWL8DnNB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor shape=(None, 20100), dtype=float32, sparse=False, name=keras_tensor_14>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[3].output # printing the output of the 4th layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F23Th9xBDnNB"
      },
      "source": [
        "**Creating a new model by reusing intermediate layer outputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OfTgxy4xDnNB"
      },
      "outputs": [],
      "source": [
        "features = model.layers[4].output # getting the output of the 5th layer\n",
        "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features) # adding a dense layer with 3 neurons and softmax activation function for the difficulty\n",
        "\n",
        "new_model = keras.Model( # defining a new model with the input and output layers\n",
        "    inputs=[title, text_body, tags], # defining the input layers with title, text_body, and tags\n",
        "    outputs=[priority, department, difficulty]) # defining the output layers with priority, department, and difficulty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ECJQGgz7DnNB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
          ]
        }
      ],
      "source": [
        "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True) # plotting the updated model with shape information and saving it as updated_ticket_classifier.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ1gSzzyDnNB"
      },
      "source": [
        "### Subclassing the Model class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgzaLKRGDnNB"
      },
      "source": [
        "#### Rewriting our previous example as a subclassed model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmURC5_uDnNB"
      },
      "source": [
        "**A simple subclassed model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ywMHu6ISDnNB"
      },
      "outputs": [],
      "source": [
        "class CustomerTicketModel(keras.Model): # defining a custom model class\n",
        "\n",
        "    def __init__(self, num_departments): # defining the constructor with the number of departments as input \n",
        "        super().__init__() # calling the constructor of the parent class\n",
        "        self.concat_layer = layers.Concatenate() # concatenating the input layers\n",
        "        self.mixing_layer = layers.Dense(64, activation=\"relu\") # adding a dense layer with 64 neurons and relu activation function\n",
        "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\") # adding a dense layer with 1 neuron and sigmoid activation function for the priority\n",
        "        self.department_classifier = layers.Dense( # adding a dense layer for the department\n",
        "            num_departments, activation=\"softmax\") # with num_departments neurons and softmax activation function\n",
        "\n",
        "    def call(self, inputs): # defining the call method with inputs as input\n",
        "        title = inputs[\"title\"] # getting the title from the inputs\n",
        "        text_body = inputs[\"text_body\"] # getting the text body from the inputs\n",
        "        tags = inputs[\"tags\"] # getting the tags from the inputs\n",
        "\n",
        "        features = self.concat_layer([title, text_body, tags]) # concatenating the input layers\n",
        "        features = self.mixing_layer(features) # passing the concatenated features to the mixing layer\n",
        "        priority = self.priority_scorer(features) # passing the mixed features to the priority scorer\n",
        "        department = self.department_classifier(features) # passing the mixed features to the department classifier\n",
        "        return priority, department # returning the priority and department"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "p_xJQsdkDnNB"
      },
      "outputs": [],
      "source": [
        "model = CustomerTicketModel(num_departments=4) # creating an instance of the custom model class with 4 departments\n",
        "\n",
        "priority, department = model( # calling the model with the input data\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cV6EDTPtDnNB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1697 - loss: 50.1776 - mean_absolute_error: 0.4810\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2349 - loss: 24.3458 - mean_absolute_error: 0.5036\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"rmsprop\", # compiling the model with rmsprop optimizer\n",
        "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"], # defining the loss functions for the priority and department\n",
        "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]]) # defining the metrics for the priority and department\n",
        "model.fit({\"title\": title_data, # training the model with the input and output data\n",
        "           \"text_body\": text_body_data, \n",
        "           \"tags\": tags_data},\n",
        "          [priority_data, department_data], \n",
        "          epochs=1) # training the model for 1 epoch\n",
        "model.evaluate({\"title\": title_data, # evaluating the model with the input and output data\n",
        "                \"text_body\": text_body_data,\n",
        "                \"tags\": tags_data},\n",
        "               [priority_data, department_data]) \n",
        "priority_preds, department_preds = model.predict({\"title\": title_data, # predicting the priority and department with the input data\n",
        "                                                  \"text_body\": text_body_data, \n",
        "                                                  \"tags\": tags_data}) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ITMGJbcDnNC"
      },
      "source": [
        "#### Beware: What subclassed models don't support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I-4eHI9DnNC"
      },
      "source": [
        "### Mixing and matching different components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmyB-Q-hDnNC"
      },
      "source": [
        "**Creating a Functional model that includes a subclassed model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "AnFLDj5SDnNC"
      },
      "outputs": [],
      "source": [
        "class Classifier(keras.Model): # defining a custom model class\n",
        "\n",
        "    def __init__(self, num_classes=2): # defining the constructor with the number of classes as input\n",
        "        super().__init__() # calling the constructor of the parent class\n",
        "        if num_classes == 2: # if the number of classes is 2\n",
        "            num_units = 1 # set the number of units to 1\n",
        "            activation = \"sigmoid\" # set the activation function to sigmoid\n",
        "        else: # if the number of classes is not 2\n",
        "            num_units = num_classes # set the number of units to the number of classes\n",
        "            activation = \"softmax\" # set the activation function to softmax\n",
        "        self.dense = layers.Dense(num_units, activation=activation) # adding a dense layer with num_units neurons and the specified activation function\n",
        "\n",
        "    def call(self, inputs): # defining the call method with inputs as input\n",
        "        return self.dense(inputs) # returning the output of the dense layer\n",
        " \n",
        "inputs = keras.Input(shape=(3,)) # defining the input layer with input shape of (None, 3) because we have 3 features in the input data\n",
        "features = layers.Dense(64, activation=\"relu\")(inputs) # adding a dense layer with 64 neurons and relu activation function\n",
        "outputs = Classifier(num_classes=10)(features) # adding a custom classifier with 10 classes\n",
        "model = keras.Model(inputs=inputs, outputs=outputs) # defining the model with the input and output layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjeG4WMtDnNC"
      },
      "source": [
        "**Creating a subclassed model that includes a Functional model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AUpCv2PCDnNC"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(64,)) # defining the input layer with input shape of (None, 64) because the output shape of the dense layer is (None, 64)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs) # adding a dense layer with 1 neuron and sigmoid activation function\n",
        "binary_classifier = keras.Model(inputs=inputs, outputs=outputs) # defining a binary classifier model with the input and output layers\n",
        "\n",
        "class MyModel(keras.Model): # defining a custom model class\n",
        "\n",
        "    def __init__(self, num_classes=2): # defining the constructor with the number of classes as input\n",
        "        super().__init__() # calling the constructor of the parent class\n",
        "        self.dense = layers.Dense(64, activation=\"relu\") # adding a dense layer with 64 neurons and relu activation function\n",
        "        self.classifier = binary_classifier # adding a binary classifier\n",
        "\n",
        "    def call(self, inputs): # defining the call method with inputs as input\n",
        "        features = self.dense(inputs) # passing the inputs to the dense layer\n",
        "        return self.classifier(features) # passing the features to the binary classifier\n",
        "\n",
        "model = MyModel() # creating an instance of the custom model class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnpDwwNNDnNC"
      },
      "source": [
        "### Remember: Use the right tool for the job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfCULVzeDnNC"
      },
      "source": [
        "## Using built-in training and evaluation loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IzbsZLiDnNC"
      },
      "source": [
        "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OrpckXLDDnNC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8673 - loss: 0.4428 - val_accuracy: 0.9578 - val_loss: 0.1454\n",
            "Epoch 2/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1706 - val_accuracy: 0.9689 - val_loss: 0.1075\n",
            "Epoch 3/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9652 - loss: 0.1257 - val_accuracy: 0.9744 - val_loss: 0.0962\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.9696 - loss: 0.1052\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist # importing mnist dataset\n",
        "\n",
        "def get_mnist_model(): # defining a function to get the mnist model\n",
        "    inputs = keras.Input(shape=(28 * 28,)) # defining the input layer with input shape of (None, 28*28) because the input data has 28*28 features\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs) # adding a dense layer with 512 neurons and relu activation function\n",
        "    features = layers.Dropout(0.5)(features) # adding a dropout layer with a dropout rate of 0.5 (the most common rate)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features) # adding a dense layer with 10 neurons and softmax activation function\n",
        "    model = keras.Model(inputs, outputs) # defining the model with the input and output layers\n",
        "    return model # returning the model\n",
        "\n",
        "(images, labels), (test_images, test_labels) = mnist.load_data() # loading the mnist dataset\n",
        "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255 # reshaping the images and normalizing them\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255 # reshaping the test images and normalizing them\n",
        "train_images, val_images = images[10000:], images[:10000] # splitting the images into training and validation sets\n",
        "train_labels, val_labels = labels[10000:], labels[:10000] # splitting the labels into training and validation sets\n",
        "\n",
        "model = get_mnist_model() # getting the mnist model\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with rmsprop optimizer\n",
        "              loss=\"sparse_categorical_crossentropy\", # defining the loss function\n",
        "              metrics=[\"accuracy\"]) # defining the metrics\n",
        "model.fit(train_images, train_labels, # training the model with the training data\n",
        "          epochs=3, # training the model for 3 epochs\n",
        "          validation_data=(val_images, val_labels)) # validating the model with the validation data\n",
        "test_metrics = model.evaluate(test_images, test_labels) # evaluating the model with the test data\n",
        "predictions = model.predict(test_images) # predicting the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZY57HchDnNC"
      },
      "source": [
        "### Writing your own metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h6cfCFrDnNC"
      },
      "source": [
        "**Implementing a custom metric by subclassing the `Metric` class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VLpOvwslDnNC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # importing tensorflow package\n",
        "\n",
        "class RootMeanSquaredError(keras.metrics.Metric): # defining a custom metric class\n",
        "\n",
        "    def __init__(self, name=\"rmse\", **kwargs): # defining the constructor with the name and keyword arguments\n",
        "        super().__init__(name=name, **kwargs) # calling the constructor of the parent class\n",
        "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\") # adding a weight for the mse sum\n",
        "        self.total_samples = self.add_weight( # adding a weight for the total number of samples\n",
        "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\") # with dtype int32 for integer values \n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None): # defining the update state method with y_true, y_pred, and sample_weight as inputs\n",
        "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1]) # converting the true labels to one-hot encoding\n",
        "        mse = tf.reduce_sum(tf.square(y_true - y_pred)) # calculating the mean squared error\n",
        "        self.mse_sum.assign_add(mse) # adding the mse to the mse sum\n",
        "        num_samples = tf.shape(y_pred)[0] # getting the number of samples\n",
        "        self.total_samples.assign_add(num_samples) # adding the number of samples to the total samples\n",
        "\n",
        "    def result(self): # defining the result method\n",
        "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32)) # returning the root mean squared error\n",
        "\n",
        "    def reset_state(self): # defining the reset state method\n",
        "        self.mse_sum.assign(0.) # assigning 0 to the mse sum\n",
        "        self.total_samples.assign(0) # assigning 0 to the total samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QWCqtptnDnNC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.4512 - rmse: 0.4404 - val_accuracy: 0.9582 - val_loss: 0.1434 - val_rmse: 0.2507\n",
            "Epoch 2/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1708 - rmse: 0.2746 - val_accuracy: 0.9659 - val_loss: 0.1166 - val_rmse: 0.2245\n",
            "Epoch 3/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1328 - rmse: 0.2421 - val_accuracy: 0.9720 - val_loss: 0.1035 - val_rmse: 0.2076\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.9695 - loss: 0.1035 - rmse: 0.2133\n"
          ]
        }
      ],
      "source": [
        "model = get_mnist_model() # getting the mnist model\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with rmsprop optimizer\n",
        "              loss=\"sparse_categorical_crossentropy\", # defining the loss function\n",
        "              metrics=[\"accuracy\", RootMeanSquaredError()]) # defining the metrics with accuracy and the custom metric\n",
        "model.fit(train_images, train_labels, # training the model with the training data\n",
        "          epochs=3, # training the model for 3 epochs\n",
        "          validation_data=(val_images, val_labels)) # validating the model with the validation data\n",
        "test_metrics = model.evaluate(test_images, test_labels) # evaluating the model with the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIWPMXqsDnNC"
      },
      "source": [
        "### Using callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCzNIthADnNC"
      },
      "source": [
        "#### The EarlyStopping and ModelCheckpoint callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzGnPZPWDnNC"
      },
      "source": [
        "**Using the `callbacks` argument in the `fit()` method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wf7BuvXUDnNC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 0.4452 - val_accuracy: 0.9575 - val_loss: 0.1432\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9525 - loss: 0.1660 - val_accuracy: 0.9666 - val_loss: 0.1160\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9617 - loss: 0.1338 - val_accuracy: 0.9728 - val_loss: 0.1023\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1173 - val_accuracy: 0.9753 - val_loss: 0.0983\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.1011 - val_accuracy: 0.9761 - val_loss: 0.0910\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9757 - loss: 0.0895 - val_accuracy: 0.9779 - val_loss: 0.0927\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.0887 - val_accuracy: 0.9794 - val_loss: 0.0837\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0797 - val_accuracy: 0.9772 - val_loss: 0.0949\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0809 - val_accuracy: 0.9785 - val_loss: 0.1009\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2e7163290>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "callbacks_list = [ # defining a list of callbacks\n",
        "    keras.callbacks.EarlyStopping( # adding an early stopping callback\n",
        "        monitor=\"val_accuracy\", # monitoring the validation accuracy\n",
        "        patience=2, # waiting for 2 epochs without improvement\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint( # adding a model checkpoint callback\n",
        "        filepath=\"checkpoint_path.keras\", # saving the model to the specified path\n",
        "        monitor=\"val_loss\", # monitoring the validation loss\n",
        "        save_best_only=True, # saving only the best model\n",
        "    )\n",
        "]\n",
        "model = get_mnist_model() # getting the mnist model\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with rmsprop optimizer\n",
        "              loss=\"sparse_categorical_crossentropy\", # defining the loss function\n",
        "              metrics=[\"accuracy\"]) # defining the metrics\n",
        "model.fit(train_images, train_labels, # training the model with the training data\n",
        "          epochs=10, # training the model for 10 epochs\n",
        "          callbacks=callbacks_list, # using the callbacks list\n",
        "          validation_data=(val_images, val_labels)) # validating the model with the validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "yZr2tuOzDnND"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"checkpoint_path.keras\") # loading the best model from the checkpoint path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb5YCf7MDnND"
      },
      "source": [
        "### Writing your own callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJNiNEYBDnND"
      },
      "source": [
        "**Creating a custom callback by subclassing the `Callback` class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HkTmaKlUDnND"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt # importing pyplot from matplotlib package\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback): # defining a custom callback class\n",
        "    def on_train_begin(self, logs): # defining the on train begin method with logs as input\n",
        "        self.per_batch_losses = [] # initializing the list of per batch losses\n",
        "\n",
        "    def on_batch_end(self, batch, logs): # defining the on batch end method with batch and logs as inputs\n",
        "        self.per_batch_losses.append(logs.get(\"loss\")) # appending the loss to the list of per batch losses\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs): # defining the on epoch end method with epoch and logs as inputs\n",
        "        plt.clf() # clearing the current figure\n",
        "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses, # plotting the per batch losses for the epoch \n",
        "                 label=\"Training loss for each batch\") # adding a label for the plot\n",
        "        plt.xlabel(f\"Batch (epoch {epoch})\") # setting the x-axis label\n",
        "        plt.ylabel(\"Loss\") # setting the y-axis label\n",
        "        plt.legend() # adding a legend to the plot\n",
        "        plt.savefig(f\"plot_at_epoch_{epoch}\") # saving the plot as a file\n",
        "        self.per_batch_losses = [] # resetting the list of per batch losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XrlQnOiyDnND"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.4522 - val_accuracy: 0.9597 - val_loss: 0.1458\n",
            "Epoch 2/10\n",
            "\u001b[1m  44/1563\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9597 - loss: 0.1452"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5j/v9msxv8n6jv_3409lgk47xph0000gn/T/ipykernel_69949/3405740079.py:17: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
            "/var/folders/5j/v9msxv8n6jv_3409lgk47xph0000gn/T/ipykernel_69949/3405740079.py:17: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
            "/var/folders/5j/v9msxv8n6jv_3409lgk47xph0000gn/T/ipykernel_69949/3405740079.py:17: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
            "/var/folders/5j/v9msxv8n6jv_3409lgk47xph0000gn/T/ipykernel_69949/3405740079.py:17: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  plt.savefig(f\"plot_at_epoch_{epoch}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.1624 - val_accuracy: 0.9689 - val_loss: 0.1131\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1328 - val_accuracy: 0.9695 - val_loss: 0.1142\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1102 - val_accuracy: 0.9731 - val_loss: 0.0986\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.1005 - val_accuracy: 0.9750 - val_loss: 0.0942\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0937 - val_accuracy: 0.9781 - val_loss: 0.0888\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.0854 - val_accuracy: 0.9757 - val_loss: 0.0981\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9761 - loss: 0.0835 - val_accuracy: 0.9775 - val_loss: 0.0917\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.0716 - val_accuracy: 0.9785 - val_loss: 0.0947\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0705 - val_accuracy: 0.9789 - val_loss: 0.0975\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2a1f510d0>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/miakuntz/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/miakuntz/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/miakuntz/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/miakuntz/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = get_mnist_model() # getting the mnist model\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with rmsprop optimizer\n",
        "              loss=\"sparse_categorical_crossentropy\", # defining the loss function\n",
        "              metrics=[\"accuracy\"]) # defining the metrics\n",
        "model.fit(train_images, train_labels, # training the model with the training data\n",
        "          epochs=10, # training the model for 10 epochs\n",
        "          callbacks=[LossHistory()], # using the custom callback\n",
        "          validation_data=(val_images, val_labels)) # validating the model with the validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPMDIDYGDnND"
      },
      "source": [
        "### Monitoring and visualization with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ksZFkhwmDnND"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-02 14:39:50.370004: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at summary_kernels.cc:65 : PERMISSION_DENIED: /full_path_to_your_log_dir; Read-only file system\n",
            "2024-04-02 14:39:50.370020: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: PERMISSION_DENIED: /full_path_to_your_log_dir; Read-only file system\n"
          ]
        },
        {
          "ename": "PermissionDeniedError",
          "evalue": "{{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} /full_path_to_your_log_dir; Read-only file system [Op:CreateSummaryFileWriter] name: ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[1;32m/Users/miakuntz/Documents/UNI/8. semester/machine learning for business intelligence 2/machine_learning_2/nbs/ch.07_working_with_keras.ipynb Cell 79\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrmsprop\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tensorboard \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     log_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/full_path_to_your_log_dir\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_images, train_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m           validation_data\u001b[39m=\u001b[39;49m(val_images, val_labels),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miakuntz/Documents/UNI/8.%20semester/machine%20learning%20for%20business%20intelligence%202/machine_learning_2/nbs/ch.07_working_with_keras.ipynb#Y141sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m           callbacks\u001b[39m=\u001b[39;49m[tensorboard])\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
            "\u001b[0;31mPermissionDeniedError\u001b[0m: {{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} /full_path_to_your_log_dir; Read-only file system [Op:CreateSummaryFileWriter] name: "
          ]
        }
      ],
      "source": [
        "model = get_mnist_model() # getting the mnist model\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with rmsprop optimizer\n",
        "              loss=\"sparse_categorical_crossentropy\", # defining the loss function\n",
        "              metrics=[\"accuracy\"]) # defining the metrics\n",
        "\n",
        "tensorboard = keras.callbacks.TensorBoard( # defining a tensorboard callback\n",
        "    log_dir=\"/full_path_to_your_log_dir\", # specifying the log directory\n",
        ")\n",
        "model.fit(train_images, train_labels, # training the model with the training data\n",
        "          epochs=10, # training the model for 10 epochs\n",
        "          validation_data=(val_images, val_labels), # validating the model with the validation data\n",
        "          callbacks=[tensorboard]) # using the tensorboard callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsE8cJEwDnND"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard # loading the tensorboard extension\n",
        "%tensorboard --logdir /full_path_to_your_log_dir # running the tensorboard with the specified log directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W795rwQ5DnND"
      },
      "source": [
        "## Writing your own training and evaluation loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zsVYn8HDnND"
      },
      "source": [
        "### Training versus inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyDSJ6OXDnND"
      },
      "source": [
        "### Low-level usage of metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osbVG5wrDnND"
      },
      "outputs": [],
      "source": [
        "metric = keras.metrics.SparseCategoricalAccuracy() # defining a sparse categorical accuracy metric\n",
        "targets = [0, 1, 2] # defining the target labels\n",
        "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]] # defining the predicted labels\n",
        "metric.update_state(targets, predictions) # updating the metric with the targets and predictions\n",
        "current_result = metric.result() # getting the current result of the metric\n",
        "print(f\"result: {current_result:.2f}\") # printing the current result of the metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVI3iyOgDnND"
      },
      "outputs": [],
      "source": [
        "values = [0, 1, 2, 3, 4] # defining a list of values\n",
        "mean_tracker = keras.metrics.Mean() # defining a mean metric\n",
        "for value in values: # iterating over the values\n",
        "    mean_tracker.update_state(value) # updating the mean metric with the value\n",
        "print(f\"Mean of values: {mean_tracker.result():.2f}\") # printing the mean of the values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7evRYIUDnND"
      },
      "source": [
        "### A complete training and evaluation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNolBterDnND"
      },
      "source": [
        "**Writing a step-by-step training loop: the training step function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J4mkLcbDnND"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model() # getting the mnist model\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy() # defining a sparse categorical crossentropy loss function\n",
        "optimizer = keras.optimizers.RMSprop() # defining an RMSprop optimizer\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()] # defining a sparse categorical accuracy metric\n",
        "loss_tracking_metric = keras.metrics.Mean() # defining a mean metric for tracking the loss\n",
        "\n",
        "def train_step(inputs, targets): # defining a training step function with inputs and targets as inputs\n",
        "    with tf.GradientTape() as tape: # using a gradient tape to record the operations\n",
        "        predictions = model(inputs, training=True) # getting the predictions from the model\n",
        "        loss = loss_fn(targets, predictions) # calculating the loss\n",
        "    gradients = tape.gradient(loss, model.trainable_weights) # calculating the gradients\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights)) # applying the gradients\n",
        "\n",
        "    logs = {} # initializing a dictionary for logs\n",
        "    for metric in metrics: # iterating over the metrics\n",
        "        metric.update_state(targets, predictions) # updating the metric with the targets and predictions\n",
        "        logs[metric.name] = metric.result() # adding the metric result to the logs\n",
        "\n",
        "    loss_tracking_metric.update_state(loss) # updating the loss tracking metric with the loss\n",
        "    logs[\"loss\"] = loss_tracking_metric.result() # adding the loss to the logs\n",
        "    return logs # returning the logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6YFIZMNDnND"
      },
      "source": [
        "**Writing a step-by-step training loop: resetting the metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h589VrkDnND"
      },
      "outputs": [],
      "source": [
        "def reset_metrics(): # defining a function to reset the metrics\n",
        "    for metric in metrics: # iterating over the metrics\n",
        "        metric.reset_state() # resetting the state of the metric\n",
        "    loss_tracking_metric.reset_state() # resetting the state of the loss tracking metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaU-26JfDnND"
      },
      "source": [
        "**Writing a step-by-step training loop: the loop itself**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb-ss_FvDnNE"
      },
      "outputs": [],
      "source": [
        "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)) # creating a training dataset\n",
        "training_dataset = training_dataset.batch(32) # batching the training dataset into batches of size 32 because it is a common batch size for training \n",
        "epochs = 3 # defining the number of epochs\n",
        "for epoch in range(epochs): # iterating over the epochs\n",
        "    reset_metrics() # resetting the metrics\n",
        "    for inputs_batch, targets_batch in training_dataset: # iterating over the training dataset\n",
        "        logs = train_step(inputs_batch, targets_batch) # performing a training step\n",
        "    print(f\"Results at the end of epoch {epoch}\") # printing the results at the end of the epoch\n",
        "    for key, value in logs.items(): # iterating over the logs\n",
        "        print(f\"...{key}: {value:.4f}\") # printing the key and value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJDLECmSDnNE"
      },
      "source": [
        "**Writing a step-by-step evaluation loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BUJA10IDnNE"
      },
      "outputs": [],
      "source": [
        "def test_step(inputs, targets): # defining a test step function with inputs and targets as inputs\n",
        "    predictions = model(inputs, training=False) # getting the predictions from the model\n",
        "    loss = loss_fn(targets, predictions) # calculating the loss\n",
        "\n",
        "    logs = {} # initializing a dictionary for logs\n",
        "    for metric in metrics: # iterating over the metrics\n",
        "        metric.update_state(targets, predictions) # updating the metric with the targets and predictions\n",
        "        logs[\"val_\" + metric.name] = metric.result() # adding the metric result to the logs\n",
        "\n",
        "    loss_tracking_metric.update_state(loss) # updating the loss tracking metric with the loss\n",
        "    logs[\"val_loss\"] = loss_tracking_metric.result() # adding the loss to the logs\n",
        "    return logs # returning the logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)) # creating a validation dataset\n",
        "val_dataset = val_dataset.batch(32) # batching the validation dataset into batches of size 32 because it is a common batch size for validation\n",
        "reset_metrics() # resetting the metrics\n",
        "for inputs_batch, targets_batch in val_dataset: # iterating over the validation dataset\n",
        "    logs = test_step(inputs_batch, targets_batch) # performing a test step\n",
        "print(\"Evaluation results:\") # printing the evaluation results\n",
        "for key, value in logs.items(): # iterating over the logs\n",
        "    print(f\"...{key}: {value:.4f}\") # printing the key and value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OUDGlzfDnNE"
      },
      "source": [
        "### Make it fast with tf.function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9a02HnUDnNE"
      },
      "source": [
        "**Adding a `tf.function` decorator to our evaluation-step function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGxipBy-DnNE"
      },
      "outputs": [],
      "source": [
        "@tf.function # defining a TensorFlow function for the training step\n",
        "def test_step(inputs, targets): # defining a test step function with inputs and targets as inputs\n",
        "    predictions = model(inputs, training=False) # getting the predictions from the model\n",
        "    loss = loss_fn(targets, predictions) # calculating the loss\n",
        "\n",
        "    logs = {} # initializing a dictionary for logs\n",
        "    for metric in metrics: # iterating over the metrics\n",
        "        metric.update_state(targets, predictions) # updating the metric with the targets and predictions\n",
        "        logs[\"val_\" + metric.name] = metric.result() # adding the metric result to the logs\n",
        "\n",
        "    loss_tracking_metric.update_state(loss) # updating the loss tracking metric with the loss\n",
        "    logs[\"val_loss\"] = loss_tracking_metric.result() # adding the loss to the logs\n",
        "    return logs # returning the logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)) # creating a validation dataset\n",
        "val_dataset = val_dataset.batch(32) # batching the validation dataset into batches of size 32 because it is a common batch size for validation\n",
        "reset_metrics() # resetting the metrics\n",
        "for inputs_batch, targets_batch in val_dataset: # iterating over the validation dataset\n",
        "    logs = test_step(inputs_batch, targets_batch) # performing a test step\n",
        "print(\"Evaluation results:\") # printing the evaluation results\n",
        "for key, value in logs.items(): # iterating over the logs\n",
        "    print(f\"...{key}: {value:.4f}\") # printing the key and value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AJx4vXWDnNE"
      },
      "source": [
        "### Leveraging fit() with a custom training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATfG7f58DnNE"
      },
      "source": [
        "**Implementing a custom training step to use with `fit()`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzjRbzk6DnNE"
      },
      "outputs": [],
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy() # defining a sparse categorical crossentropy loss function\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\") # defining a mean metric for tracking the loss\n",
        "\n",
        "class CustomModel(keras.Model): # defining a custom model class\n",
        "    def train_step(self, data): # defining a train step method with data as input\n",
        "        inputs, targets = data # getting the inputs and targets from the data\n",
        "        with tf.GradientTape() as tape: # using a gradient tape to record the operations\n",
        "            predictions = self(inputs, training=True) # getting the predictions from the model\n",
        "            loss = loss_fn(targets, predictions) # calculating the loss\n",
        "        gradients = tape.gradient(loss, self.trainable_weights) # calculating the gradients\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights)) # applying the gradients\n",
        "\n",
        "        loss_tracker.update_state(loss) # updating the loss tracker with the loss\n",
        "        return {\"loss\": loss_tracker.result()} # returning the loss\n",
        "\n",
        "    @property # defining a property\n",
        "    def metrics(self): # defining a metrics method\n",
        "        return [loss_tracker] # returning the loss tracker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HoEe9jKDnNE"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(28 * 28,)) # defining the input layer with input shape of (None, 28*28) because the input data has 28*28 features\n",
        "features = layers.Dense(512, activation=\"relu\")(inputs) # adding a dense layer with 512 neurons and relu activation function\n",
        "features = layers.Dropout(0.5)(features) # adding a dropout layer with a dropout rate of 0.5 (the most common rate)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features) # adding a dense layer with 10 neurons and softmax activation function\n",
        "model = CustomModel(inputs, outputs) # defining the model with the input and output layers\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop()) # compiling the model with rmsprop optimizer\n",
        "model.fit(train_images, train_labels, epochs=3) # training the model with the training data for 3 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg7bVfGDDnNE"
      },
      "outputs": [],
      "source": [
        "class CustomModel(keras.Model): # defining a custom model class\n",
        "    def train_step(self, data): # defining a train step method with data as input\n",
        "        inputs, targets = data # getting the inputs and targets from the data\n",
        "        with tf.GradientTape() as tape: # using a gradient tape to record the operations\n",
        "            predictions = self(inputs, training=True) # getting the predictions from the model\n",
        "            loss = self.compiled_loss(targets, predictions) # calculating the loss\n",
        "        gradients = tape.gradient(loss, self.trainable_weights) # calculating the gradients\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights)) # applying the gradients\n",
        "        self.compiled_metrics.update_state(targets, predictions) # updating the metrics with the targets and predictions\n",
        "        return {m.name: m.result() for m in self.metrics} # returning the metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAMHrZ-VDnNE"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(28 * 28,)) # defining the input layer with input shape of (None, 28*28) because the input data has 28*28 features\n",
        "features = layers.Dense(512, activation=\"relu\")(inputs) # adding a dense layer with 512 neurons and relu activation function\n",
        "features = layers.Dropout(0.5)(features) # adding a dropout layer with a dropout rate of 0.5 (the most common rate)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features) # adding a dense layer with 10 neurons and softmax activation function\n",
        "model = CustomModel(inputs, outputs) # defining the model with the input and output layers\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(), # compiling the model with rmsprop optimizer\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(), # defining the loss function\n",
        "              metrics=[keras.metrics.SparseCategoricalAccuracy()]) # defining the metrics\n",
        "model.fit(train_images, train_labels, epochs=3) # training the model with the training data for 3 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuKZJXyADnNE"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter07_working-with-keras.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
