{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPaIYD7L4EqT"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q2hU9_i4EqV"
      },
      "source": [
        "# Fundamentals of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LhFuTJ84EqV"
      },
      "source": [
        "## Generalization: The goal of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCVFIPsx4EqW"
      },
      "source": [
        "### Underfitting and overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE177rJd4EqW"
      },
      "source": [
        "#### Noisy training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8odH4tF4EqW"
      },
      "source": [
        "#### Ambiguous features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05drgXGP4EqW"
      },
      "source": [
        "#### Rare features and spurious correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaRvsw3k4EqW"
      },
      "source": [
        "**Adding white-noise channels or all-zeros channels to MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lbipXIR94EqW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist # importing the mnist dataset from keras library \n",
        "import numpy as np # importing numpy library to work with arrays \n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data() # loading the mnist dataset into train_images and train_labels \n",
        "train_images = train_images.reshape((60000, 28 * 28)) # reshaping the train_images to 60000, 28*28 because the images are 28*28 pixels that are flattened into 1D array \n",
        "train_images = train_images.astype(\"float32\") / 255 # normalizing the train_images by dividing by 255 to get values between 0 and 1\n",
        "\n",
        "train_images_with_noise_channels = np.concatenate( # adding random noise to the train_images because the model will be trained on noisy images which will help the model to generalize better\n",
        "    [train_images, np.random.random((len(train_images), 784))], axis=1) # adding random noise to the train_images by adding random values between 0 and 1 to the train_images which will be used as input to the model \n",
        "\n",
        "train_images_with_zeros_channels = np.concatenate( # adding zeros to the train_images because the model will be trained on images with zeros which will help the model to generalize better\n",
        "    [train_images, np.zeros((len(train_images), 784))], axis=1) # adding zeros to the train_images that will be used as input to the model which will help the model to generalize better "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cizQe8u64EqX"
      },
      "source": [
        "**Training the same model on MNIST data with noise channels or all-zero channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D9vTCqbB4EqX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6213 - accuracy: 0.8120 - val_loss: 0.2729 - val_accuracy: 0.9188\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2498 - accuracy: 0.9235 - val_loss: 0.2004 - val_accuracy: 0.9387\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1651 - accuracy: 0.9492 - val_loss: 0.1377 - val_accuracy: 0.9579\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1167 - accuracy: 0.9631 - val_loss: 0.1326 - val_accuracy: 0.9601\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0863 - accuracy: 0.9730 - val_loss: 0.1504 - val_accuracy: 0.9582\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0632 - accuracy: 0.9801 - val_loss: 0.1196 - val_accuracy: 0.9679\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0466 - accuracy: 0.9848 - val_loss: 0.1230 - val_accuracy: 0.9680\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.1458 - val_accuracy: 0.9632\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.1223 - val_accuracy: 0.9692\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.1747 - val_accuracy: 0.9611\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2849 - accuracy: 0.9176 - val_loss: 0.1703 - val_accuracy: 0.9498\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1178 - accuracy: 0.9652 - val_loss: 0.1138 - val_accuracy: 0.9647\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0778 - accuracy: 0.9769 - val_loss: 0.0914 - val_accuracy: 0.9740\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0553 - accuracy: 0.9843 - val_loss: 0.0861 - val_accuracy: 0.9762\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0410 - accuracy: 0.9883 - val_loss: 0.0824 - val_accuracy: 0.9768\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9908 - val_loss: 0.0824 - val_accuracy: 0.9757\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 0.0907 - val_accuracy: 0.9763\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.0752 - val_accuracy: 0.9808\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0847 - val_accuracy: 0.9797\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0799 - val_accuracy: 0.9807\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras # importing keras from tensorflow library\n",
        "from tensorflow.keras import layers # importing layers from keras library\n",
        "\n",
        "def get_model(): # defining a function to get the model\n",
        "    model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "        layers.Dense(512, activation=\"relu\"), # adding a dense layer with 512 neurons and relu activation function (this is the input layer that takes the input and passes it to the hidden layer) \n",
        "        layers.Dense(10, activation=\"softmax\") # adding a dense layer with 10 neurons and softmax activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\", # compiling the model with optimizer as rmsprop which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "                  loss=\"sparse_categorical_crossentropy\", # setting loss function as sparse_categorical_crossentropy which is used for multi-class classification problems where the output labels are integers\n",
        "                  metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model \n",
        "    return model # returning the model\n",
        "\n",
        "model = get_model() # getting the model\n",
        "history_noise = model.fit( # fitting the model with train_images_with_noise_channels and train_labels by training the model on noisy images which will help the model to generalize better\n",
        "    train_images_with_noise_channels, train_labels, \n",
        "    epochs=10, # setting the epochs as 10 (number of times the model will be trained on the dataset)\n",
        "    batch_size=128, # setting the batch size as 128 (number of samples that will be used to train the model at once)\n",
        "    validation_split=0.2) # setting the validation split as 0.2 (percentage of the dataset that will be used for validation)\n",
        "\n",
        "model = get_model() # getting the model\n",
        "history_zeros = model.fit( # fitting the model with train_images_with_zeros_channels and train_labels by training the model on images with zeros which will help the model to generalize better\n",
        "    train_images_with_zeros_channels, train_labels,\n",
        "    epochs=10, # setting the epochs as 10 (number of times the model will be trained on the dataset)\n",
        "    batch_size=128, # setting the batch size as 128 (number of samples that will be used to train the model at once)\n",
        "    validation_split=0.2) # setting the validation split as 0.2 (percentage of the dataset that will be used for validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-lK9trB4EqY"
      },
      "source": [
        "**Plotting a validation accuracy comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eF2v10i14EqY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x17e50a810>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/miakuntz/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/miakuntz/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/miakuntz/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/miakuntz/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt # importing matplotlib library to plot the graph\n",
        "val_acc_noise = history_noise.history[\"val_accuracy\"] # getting the validation accuracy from history_noise\n",
        "val_acc_zeros = history_zeros.history[\"val_accuracy\"] # getting the validation accuracy from history_zeros\n",
        "epochs = range(1, 11) # setting the epochs as 1 to 11\n",
        "plt.plot(epochs, val_acc_noise, \"b-\", # plotting the graph with epochs, val_acc_noise and val_acc_zeros\n",
        "         label=\"Validation accuracy with noise channels\") # setting the label as Validation accuracy with noise channels\n",
        "plt.plot(epochs, val_acc_zeros, \"b--\", # plotting the graph with epochs, val_acc_noise and val_acc_zeros\n",
        "         label=\"Validation accuracy with zeros channels\") # setting the label as Validation accuracy with zeros channels\n",
        "plt.title(\"Effect of noise channels on validation accuracy\") # setting the title of the graph\n",
        "plt.xlabel(\"Epochs\") # setting the x-axis label as Epochs\n",
        "plt.ylabel(\"Accuracy\") # setting the y-axis label as Accuracy\n",
        "plt.legend() # setting the legend \n",
        "# The graph shows that the model trained on noisy images has better validation accuracy compared to the model trained on images with zeros which shows that adding noise to the images helps the model to generalize better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtx0Uskc4EqY"
      },
      "source": [
        "### The nature of generalization in deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxzCAh8D4EqY"
      },
      "source": [
        "**Fitting a MNIST model with randomly shuffled labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZcOcGbuJ4EqY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3182 - accuracy: 0.1021 - val_loss: 2.3061 - val_accuracy: 0.1066\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.3002 - accuracy: 0.1160 - val_loss: 2.3099 - val_accuracy: 0.1003\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.2906 - accuracy: 0.1266 - val_loss: 2.3164 - val_accuracy: 0.1047\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.2768 - accuracy: 0.1385 - val_loss: 2.3271 - val_accuracy: 0.0986\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.2588 - accuracy: 0.1547 - val_loss: 2.3373 - val_accuracy: 0.1001\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.2382 - accuracy: 0.1700 - val_loss: 2.3510 - val_accuracy: 0.1015\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.2126 - accuracy: 0.1845 - val_loss: 2.3727 - val_accuracy: 0.1015\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.1864 - accuracy: 0.1997 - val_loss: 2.3864 - val_accuracy: 0.1042\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.1559 - accuracy: 0.2173 - val_loss: 2.4121 - val_accuracy: 0.0981\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.1253 - accuracy: 0.2305 - val_loss: 2.4268 - val_accuracy: 0.1017\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.0904 - accuracy: 0.2489 - val_loss: 2.4457 - val_accuracy: 0.1020\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.0571 - accuracy: 0.2629 - val_loss: 2.4771 - val_accuracy: 0.1002\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.0222 - accuracy: 0.2762 - val_loss: 2.5042 - val_accuracy: 0.1018\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.9872 - accuracy: 0.2950 - val_loss: 2.5428 - val_accuracy: 0.0962\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.9526 - accuracy: 0.3112 - val_loss: 2.5654 - val_accuracy: 0.0995\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9166 - accuracy: 0.3227 - val_loss: 2.6073 - val_accuracy: 0.0998\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.8825 - accuracy: 0.3371 - val_loss: 2.6425 - val_accuracy: 0.1047\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.8486 - accuracy: 0.3519 - val_loss: 2.6867 - val_accuracy: 0.1044\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.8156 - accuracy: 0.3655 - val_loss: 2.7145 - val_accuracy: 0.1005\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.7824 - accuracy: 0.3780 - val_loss: 2.7754 - val_accuracy: 0.0997\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.7495 - accuracy: 0.3909 - val_loss: 2.7888 - val_accuracy: 0.1016\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.7164 - accuracy: 0.4034 - val_loss: 2.8364 - val_accuracy: 0.1035\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.6869 - accuracy: 0.4151 - val_loss: 2.8682 - val_accuracy: 0.0991\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.6579 - accuracy: 0.4257 - val_loss: 2.9079 - val_accuracy: 0.1028\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.6271 - accuracy: 0.4386 - val_loss: 2.9615 - val_accuracy: 0.0967\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.5981 - accuracy: 0.4487 - val_loss: 2.9852 - val_accuracy: 0.1008\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.5706 - accuracy: 0.4582 - val_loss: 3.0368 - val_accuracy: 0.1022\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5403 - accuracy: 0.4723 - val_loss: 3.1087 - val_accuracy: 0.0992\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5126 - accuracy: 0.4815 - val_loss: 3.1277 - val_accuracy: 0.1017\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.4860 - accuracy: 0.4918 - val_loss: 3.1767 - val_accuracy: 0.1022\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.4594 - accuracy: 0.5029 - val_loss: 3.2310 - val_accuracy: 0.0999\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4348 - accuracy: 0.5099 - val_loss: 3.2696 - val_accuracy: 0.0993\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.4096 - accuracy: 0.5177 - val_loss: 3.3313 - val_accuracy: 0.0985\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.3876 - accuracy: 0.5276 - val_loss: 3.3510 - val_accuracy: 0.0998\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.3617 - accuracy: 0.5361 - val_loss: 3.4189 - val_accuracy: 0.1020\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.3390 - accuracy: 0.5460 - val_loss: 3.4717 - val_accuracy: 0.1013\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3156 - accuracy: 0.5536 - val_loss: 3.5038 - val_accuracy: 0.1003\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.2925 - accuracy: 0.5623 - val_loss: 3.5505 - val_accuracy: 0.0995\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.2701 - accuracy: 0.5680 - val_loss: 3.5983 - val_accuracy: 0.1030\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.2485 - accuracy: 0.5782 - val_loss: 3.6497 - val_accuracy: 0.1017\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2274 - accuracy: 0.5844 - val_loss: 3.7453 - val_accuracy: 0.1017\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.2092 - accuracy: 0.5926 - val_loss: 3.7716 - val_accuracy: 0.1026\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.1885 - accuracy: 0.5989 - val_loss: 3.8015 - val_accuracy: 0.1013\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.1680 - accuracy: 0.6060 - val_loss: 3.8620 - val_accuracy: 0.0970\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.1478 - accuracy: 0.6147 - val_loss: 3.9340 - val_accuracy: 0.0983\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.1304 - accuracy: 0.6189 - val_loss: 3.9858 - val_accuracy: 0.1031\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.1129 - accuracy: 0.6260 - val_loss: 4.0252 - val_accuracy: 0.1014\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.0924 - accuracy: 0.6316 - val_loss: 4.1119 - val_accuracy: 0.1032\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.0748 - accuracy: 0.6396 - val_loss: 4.1437 - val_accuracy: 0.1016\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.0564 - accuracy: 0.6460 - val_loss: 4.1999 - val_accuracy: 0.0989\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.0398 - accuracy: 0.6526 - val_loss: 4.2869 - val_accuracy: 0.1009\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1.0255 - accuracy: 0.6560 - val_loss: 4.2926 - val_accuracy: 0.0976\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0080 - accuracy: 0.6630 - val_loss: 4.3747 - val_accuracy: 0.0987\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9908 - accuracy: 0.6684 - val_loss: 4.4423 - val_accuracy: 0.1018\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9759 - accuracy: 0.6751 - val_loss: 4.5015 - val_accuracy: 0.0997\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.9598 - accuracy: 0.6780 - val_loss: 4.5367 - val_accuracy: 0.1013\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.9446 - accuracy: 0.6858 - val_loss: 4.6165 - val_accuracy: 0.0986\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.9288 - accuracy: 0.6910 - val_loss: 4.6748 - val_accuracy: 0.1012\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.9138 - accuracy: 0.6970 - val_loss: 4.7631 - val_accuracy: 0.1013\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.9001 - accuracy: 0.6999 - val_loss: 4.7887 - val_accuracy: 0.1042\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.8855 - accuracy: 0.7063 - val_loss: 4.8427 - val_accuracy: 0.0979\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.8701 - accuracy: 0.7115 - val_loss: 4.9112 - val_accuracy: 0.1008\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.8579 - accuracy: 0.7147 - val_loss: 5.0126 - val_accuracy: 0.1007\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.8453 - accuracy: 0.7207 - val_loss: 5.0557 - val_accuracy: 0.0961\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.8292 - accuracy: 0.7274 - val_loss: 5.1061 - val_accuracy: 0.0987\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.8162 - accuracy: 0.7319 - val_loss: 5.1634 - val_accuracy: 0.0982\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.8036 - accuracy: 0.7351 - val_loss: 5.1983 - val_accuracy: 0.0992\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7930 - accuracy: 0.7396 - val_loss: 5.2978 - val_accuracy: 0.1014\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7817 - accuracy: 0.7419 - val_loss: 5.3514 - val_accuracy: 0.0993\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7689 - accuracy: 0.7470 - val_loss: 5.3851 - val_accuracy: 0.0994\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7554 - accuracy: 0.7536 - val_loss: 5.5000 - val_accuracy: 0.0984\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7454 - accuracy: 0.7547 - val_loss: 5.5260 - val_accuracy: 0.1034\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7325 - accuracy: 0.7603 - val_loss: 5.6243 - val_accuracy: 0.0968\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7225 - accuracy: 0.7640 - val_loss: 5.6962 - val_accuracy: 0.1001\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7103 - accuracy: 0.7693 - val_loss: 5.8182 - val_accuracy: 0.1009\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7014 - accuracy: 0.7704 - val_loss: 5.8228 - val_accuracy: 0.0984\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6906 - accuracy: 0.7748 - val_loss: 5.9221 - val_accuracy: 0.0978\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6784 - accuracy: 0.7795 - val_loss: 5.9083 - val_accuracy: 0.0993\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6696 - accuracy: 0.7808 - val_loss: 6.0095 - val_accuracy: 0.0988\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6594 - accuracy: 0.7875 - val_loss: 6.0811 - val_accuracy: 0.0991\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6485 - accuracy: 0.7889 - val_loss: 6.1485 - val_accuracy: 0.1002\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6375 - accuracy: 0.7929 - val_loss: 6.1821 - val_accuracy: 0.1002\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6285 - accuracy: 0.7950 - val_loss: 6.2679 - val_accuracy: 0.0976\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6199 - accuracy: 0.7985 - val_loss: 6.3367 - val_accuracy: 0.0972\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6099 - accuracy: 0.8022 - val_loss: 6.4060 - val_accuracy: 0.0978\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6023 - accuracy: 0.8034 - val_loss: 6.4754 - val_accuracy: 0.0996\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.8085 - val_loss: 6.5446 - val_accuracy: 0.0967\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5843 - accuracy: 0.8101 - val_loss: 6.6262 - val_accuracy: 0.0963\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5754 - accuracy: 0.8149 - val_loss: 6.6880 - val_accuracy: 0.1023\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.8173 - val_loss: 6.7729 - val_accuracy: 0.0962\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5589 - accuracy: 0.8198 - val_loss: 6.7961 - val_accuracy: 0.0988\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.8225 - val_loss: 6.8898 - val_accuracy: 0.0964\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.8261 - val_loss: 6.9685 - val_accuracy: 0.0988\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.8287 - val_loss: 7.0291 - val_accuracy: 0.0977\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.8304 - val_loss: 7.1115 - val_accuracy: 0.0989\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.8333 - val_loss: 7.1915 - val_accuracy: 0.0993\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5120 - accuracy: 0.8359 - val_loss: 7.2473 - val_accuracy: 0.0969\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.8392 - val_loss: 7.3664 - val_accuracy: 0.0998\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4961 - accuracy: 0.8411 - val_loss: 7.4022 - val_accuracy: 0.0971\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.8445 - val_loss: 7.4250 - val_accuracy: 0.0976\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x17e017e90>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data() # loading the mnist dataset into train_images and train_labels\n",
        "train_images = train_images.reshape((60000, 28 * 28)) # reshaping the train_images to 60000, 28*28 because the images are 28*28 pixels that are flattened into 1D array\n",
        "train_images = train_images.astype(\"float32\") / 255 # normalizing the train_images by dividing by 255 to get values between 0 and 1\n",
        "\n",
        "random_train_labels = train_labels[:] # copying the train_labels to random_train_labels\n",
        "np.random.shuffle(random_train_labels) # shuffling the random_train_labels to get random labels which will be used to train the model \n",
        "\n",
        "model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "    layers.Dense(512, activation=\"relu\"), # adding a dense layer with 512 neurons and relu activation function (this is the input layer that takes the input and passes it to the hidden layer)\n",
        "    layers.Dense(10, activation=\"softmax\") # adding a dense layer with 10 neurons and softmax activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with optimizer as rmsprop which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"sparse_categorical_crossentropy\", # setting loss function as sparse_categorical_crossentropy which is used for multi-class classification problems where the output labels are integers\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "model.fit(train_images, random_train_labels, # fitting the model with train_images and random_train_labels by training the model on random labels which will help the model to generalize better\n",
        "          epochs=100, # setting the epochs as 100 (number of times the model will be trained on the dataset)\n",
        "          batch_size=128, # setting the batch size as 128 (number of samples that will be used to train the model at once)\n",
        "          validation_split=0.2) # setting the validation split as 0.2 (percentage of the dataset that will be used for validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOMfZoWq4EqY"
      },
      "source": [
        "#### The manifold hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NThIkWq64EqY"
      },
      "source": [
        "#### Interpolation as a source of generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slR-VKyq4EqZ"
      },
      "source": [
        "#### Why deep learning works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTX5peVc4EqZ"
      },
      "source": [
        "#### Training data is paramount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiciTAb84EqZ"
      },
      "source": [
        "## Evaluating machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8twmDSJ4EqZ"
      },
      "source": [
        "### Training, validation, and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sIJ1bvi4EqZ"
      },
      "source": [
        "#### Simple hold-out validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3wKV9Rf4EqZ"
      },
      "source": [
        "#### K-fold validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4q6MT6K4EqZ"
      },
      "source": [
        "#### Iterated K-fold validation with shuffling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCLyZQ7l4EqZ"
      },
      "source": [
        "### Beating a common-sense baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2yjYo204EqZ"
      },
      "source": [
        "### Things to keep in mind about model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSBpaXPB4EqZ"
      },
      "source": [
        "## Improving model fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYj3QcsN4EqZ"
      },
      "source": [
        "### Tuning key gradient descent parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eizc9KFk4Eqa"
      },
      "source": [
        "**Training a MNIST model with an incorrectly high learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JR5iNh-U4Eqa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 1188.9053 - accuracy: 0.3777 - val_loss: 5.9273 - val_accuracy: 0.3316\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 4.0547 - accuracy: 0.2788 - val_loss: 2.5193 - val_accuracy: 0.2208\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.9274 - accuracy: 0.2376 - val_loss: 3.3657 - val_accuracy: 0.2562\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.9639 - accuracy: 0.2516 - val_loss: 2.7136 - val_accuracy: 0.2236\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.7515 - accuracy: 0.2619 - val_loss: 2.1507 - val_accuracy: 0.2654\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.8453 - accuracy: 0.2481 - val_loss: 2.0756 - val_accuracy: 0.2397\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.6804 - accuracy: 0.2527 - val_loss: 2.2322 - val_accuracy: 0.2806\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.5317 - accuracy: 0.2566 - val_loss: 2.2683 - val_accuracy: 0.2579\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.5679 - accuracy: 0.2811 - val_loss: 3.6941 - val_accuracy: 0.3153\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 2.4548 - accuracy: 0.2617 - val_loss: 1.9893 - val_accuracy: 0.2872\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x17fa7e750>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data() # loading the mnist dataset into train_images and train_labels\n",
        "train_images = train_images.reshape((60000, 28 * 28)) # reshaping the train_images to 60000, 28*28 because the images are 28*28 pixels that are flattened into 1D array\n",
        "train_images = train_images.astype(\"float32\") / 255 # normalizing the train_images by dividing by 255 to get values between 0 and 1\n",
        "\n",
        "model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "    layers.Dense(512, activation=\"relu\"), # adding a dense layer with 512 neurons and relu activation function (this is the input layer that takes the input and passes it to the hidden layer)\n",
        "    layers.Dense(10, activation=\"softmax\") # adding a dense layer with 10 neurons and softmax activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1.), # compiling the model with optimizer as RMSprop with learning rate as 1.0 which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"sparse_categorical_crossentropy\", # setting loss function as sparse_categorical_crossentropy which is used for multi-class classification problems where the output labels are integers\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "model.fit(train_images, train_labels, # fitting the model with train_images and train_labels by training the model with learning rate as 1.0 which will help the model to generalize better\n",
        "          epochs=10, # setting the epochs as 10 (number of times the model will be trained on the dataset)\n",
        "          batch_size=128, # setting the batch size as 128 (number of samples that will be used to train the model at once)\n",
        "          validation_split=0.2) # setting the validation split as 0.2 (percentage of the dataset that will be used for validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmN1X7v54Eqa"
      },
      "source": [
        "**The same model with a more appropriate learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OXUCUs2p4Eqa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.9125 - val_loss: 0.2008 - val_accuracy: 0.9505\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.1385 - accuracy: 0.9644 - val_loss: 0.1505 - val_accuracy: 0.9653\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.1167 - accuracy: 0.9735 - val_loss: 0.1669 - val_accuracy: 0.9670\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9777 - val_loss: 0.1909 - val_accuracy: 0.9672\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.0861 - accuracy: 0.9811 - val_loss: 0.2191 - val_accuracy: 0.9690\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.0722 - accuracy: 0.9851 - val_loss: 0.2009 - val_accuracy: 0.9724\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.9859 - val_loss: 0.2190 - val_accuracy: 0.9732\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.9874 - val_loss: 0.2447 - val_accuracy: 0.9712\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9894 - val_loss: 0.2488 - val_accuracy: 0.9728\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9908 - val_loss: 0.3175 - val_accuracy: 0.9737\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x17aa6ea10>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "    layers.Dense(512, activation=\"relu\"), # adding a dense layer with 512 neurons and relu activation function (this is the input layer that takes the input and passes it to the hidden layer)\n",
        "    layers.Dense(10, activation=\"softmax\") # adding a dense layer with 10 neurons and softmax activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-2), # compiling the model with optimizer as RMSprop with learning rate as 0.01 which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"sparse_categorical_crossentropy\", # setting loss function as sparse_categorical_crossentropy which is used for multi-class classification problems where the output labels are integers\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "model.fit(train_images, train_labels, # fitting the model with train_images and train_labels by training the model with learning rate as 0.01 which will help the model to generalize better\n",
        "          epochs=10, # setting the epochs as 10 (number of times the model will be trained on the dataset)\n",
        "          batch_size=128, # setting the batch size as 128 (number of samples that will be used to train the model at once)\n",
        "          validation_split=0.2) # setting the validation split as 0.2 (percentage of the dataset that will be used for validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_l-Ontx4Eqa"
      },
      "source": [
        "### Leveraging better architecture priors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xESArUpi4Eqb"
      },
      "source": [
        "### Increasing model capacity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi_NSTSt4Eqb"
      },
      "source": [
        "**A simple logistic regression on MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jTgXHGaL4Eqb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 0s 780us/step - loss: 0.6675 - accuracy: 0.8354 - val_loss: 0.3557 - val_accuracy: 0.9062\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 0s 512us/step - loss: 0.3501 - accuracy: 0.9035 - val_loss: 0.3085 - val_accuracy: 0.9160\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 0s 514us/step - loss: 0.3146 - accuracy: 0.9128 - val_loss: 0.2903 - val_accuracy: 0.9184\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 0s 530us/step - loss: 0.2987 - accuracy: 0.9165 - val_loss: 0.2828 - val_accuracy: 0.9211\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 0s 513us/step - loss: 0.2889 - accuracy: 0.9198 - val_loss: 0.2760 - val_accuracy: 0.9239\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 0s 512us/step - loss: 0.2826 - accuracy: 0.9208 - val_loss: 0.2721 - val_accuracy: 0.9257\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 0s 508us/step - loss: 0.2777 - accuracy: 0.9227 - val_loss: 0.2684 - val_accuracy: 0.9280\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 0s 568us/step - loss: 0.2739 - accuracy: 0.9234 - val_loss: 0.2670 - val_accuracy: 0.9267\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 0s 511us/step - loss: 0.2707 - accuracy: 0.9247 - val_loss: 0.2673 - val_accuracy: 0.9282\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 0s 512us/step - loss: 0.2681 - accuracy: 0.9259 - val_loss: 0.2652 - val_accuracy: 0.9283\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 0s 507us/step - loss: 0.2664 - accuracy: 0.9268 - val_loss: 0.2621 - val_accuracy: 0.9300\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 0s 521us/step - loss: 0.2643 - accuracy: 0.9272 - val_loss: 0.2645 - val_accuracy: 0.9283\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 0s 515us/step - loss: 0.2631 - accuracy: 0.9267 - val_loss: 0.2630 - val_accuracy: 0.9298\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 0s 511us/step - loss: 0.2616 - accuracy: 0.9277 - val_loss: 0.2626 - val_accuracy: 0.9296\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 0s 512us/step - loss: 0.2601 - accuracy: 0.9286 - val_loss: 0.2614 - val_accuracy: 0.9299\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 0s 520us/step - loss: 0.2590 - accuracy: 0.9291 - val_loss: 0.2605 - val_accuracy: 0.9303\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 0s 513us/step - loss: 0.2581 - accuracy: 0.9292 - val_loss: 0.2619 - val_accuracy: 0.9306\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 0s 507us/step - loss: 0.2571 - accuracy: 0.9298 - val_loss: 0.2618 - val_accuracy: 0.9307\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 0s 559us/step - loss: 0.2562 - accuracy: 0.9300 - val_loss: 0.2629 - val_accuracy: 0.9302\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 0s 511us/step - loss: 0.2552 - accuracy: 0.9302 - val_loss: 0.2607 - val_accuracy: 0.9308\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")]) # creating a sequential model with a dense layer with 10 neurons and softmax activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with optimizer as rmsprop which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"sparse_categorical_crossentropy\", # setting loss function as sparse_categorical_crossentropy which is used for multi-class classification problems where the output labels are integers\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "history_small_model = model.fit( # fitting the model with train_images and train_labels by training the model with a small model which will help the model to generalize better\n",
        "    train_images, train_labels, \n",
        "    epochs=20, # setting the epochs as 20 (number of times the model will be trained on the dataset)\n",
        "    batch_size=128, # setting the batch size as 128 (number of samples that will be used to train the model at once)\n",
        "    validation_split=0.2) # setting the validation split as 0.2 (percentage of the dataset that will be used for validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6zf6OvYx4Eqb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x2957f2990>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt # importing matplotlib library to plot the graph\n",
        "val_loss = history_small_model.history[\"val_loss\"] # getting the validation loss from history_small_model\n",
        "epochs = range(1, 21) # setting the epochs as 1 to 21\n",
        "plt.plot(epochs, val_loss, \"b--\", # plotting the graph with epochs and val_loss\n",
        "         label=\"Validation loss\") # setting the label as Validation loss\n",
        "plt.title(\"Effect of insufficient model capacity on validation loss\") # setting the title of the graph\n",
        "plt.xlabel(\"Epochs\") # setting the x-axis label as Epochs\n",
        "plt.ylabel(\"Loss\") # setting the y-axis label as Loss\n",
        "plt.legend() # setting the legend\n",
        "# The graph shows that the model with insufficient model capacity has higher validation loss which shows that the model is not able to generalize well because of insufficient model capacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZJwhdtLf4Eqc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.8966 - val_loss: 0.2032 - val_accuracy: 0.9402\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 0s 995us/step - loss: 0.1573 - accuracy: 0.9536 - val_loss: 0.1370 - val_accuracy: 0.9582\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 0s 978us/step - loss: 0.1096 - accuracy: 0.9669 - val_loss: 0.1133 - val_accuracy: 0.9660\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9743 - val_loss: 0.1010 - val_accuracy: 0.9707\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 0s 983us/step - loss: 0.0689 - accuracy: 0.9792 - val_loss: 0.1024 - val_accuracy: 0.9714\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 0s 1000us/step - loss: 0.0567 - accuracy: 0.9829 - val_loss: 0.0894 - val_accuracy: 0.9740\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 0s 976us/step - loss: 0.0467 - accuracy: 0.9861 - val_loss: 0.0885 - val_accuracy: 0.9739\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.0882 - val_accuracy: 0.9766\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 0s 983us/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.0922 - val_accuracy: 0.9753\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 0s 999us/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.0934 - val_accuracy: 0.9755\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 0s 977us/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 0.1052 - val_accuracy: 0.9705\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 0s 997us/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.1028 - val_accuracy: 0.9750\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 0s 989us/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.1092 - val_accuracy: 0.9753\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 0s 991us/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.1074 - val_accuracy: 0.9768\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 0s 997us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.1100 - val_accuracy: 0.9784\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1142 - val_accuracy: 0.9755\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 0s 981us/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.1195 - val_accuracy: 0.9760\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1203 - val_accuracy: 0.9765\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1245 - val_accuracy: 0.9766\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 0s 994us/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1515 - val_accuracy: 0.9734\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "    layers.Dense(96, activation=\"relu\"), # adding a dense layer with 96 neurons and relu activation function (this is the input layer that takes the input and passes it to the hidden layer)\n",
        "    layers.Dense(96, activation=\"relu\"), # adding a dense layer with 96 neurons and relu activation function (this is the hidden layer that takes the input from the input layer and passes it to the output layer)\n",
        "    layers.Dense(10, activation=\"softmax\"), # adding a dense layer with 10 neurons and softmax activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with optimizer as rmsprop which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"sparse_categorical_crossentropy\", # setting loss function as sparse_categorical_crossentropy which is used for multi-class classification problems where the output labels are integers\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "history_large_model = model.fit( # fitting the model with train_images and train_labels by training the model with a large model which will help the model to generalize better\n",
        "    train_images, train_labels,\n",
        "    epochs=20, # setting the epochs as 20 (number of times the model will be trained on the dataset)\n",
        "    batch_size=128, # setting the batch size as 128 (number of samples that will be used to train the model at once)\n",
        "    validation_split=0.2) # setting the validation split as 0.2 (percentage of the dataset that will be used for validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwJP1Wpp4Eqd"
      },
      "source": [
        "## Improving generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm_RmJdN4Eqe"
      },
      "source": [
        "### Dataset curation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGBEUsLK4Eqe"
      },
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlnE7Wd-4Eqe"
      },
      "source": [
        "### Using early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L68mEeno4Eqf"
      },
      "source": [
        "### Regularizing your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYJE9Pvz4Eqf"
      },
      "source": [
        "#### Reducing the network's size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdBZLJdP4Eqg"
      },
      "source": [
        "**Original model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e_whjxsl4Eqg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5109 - accuracy: 0.7838 - val_loss: 0.3810 - val_accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.3031 - accuracy: 0.9035 - val_loss: 0.3122 - val_accuracy: 0.8775\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2219 - accuracy: 0.9263 - val_loss: 0.2821 - val_accuracy: 0.8900\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1762 - accuracy: 0.9422 - val_loss: 0.2732 - val_accuracy: 0.8913\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.1461 - accuracy: 0.9529 - val_loss: 0.2806 - val_accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1219 - accuracy: 0.9603 - val_loss: 0.3041 - val_accuracy: 0.8837\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1026 - accuracy: 0.9699 - val_loss: 0.3079 - val_accuracy: 0.8844\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0860 - accuracy: 0.9754 - val_loss: 0.3321 - val_accuracy: 0.8812\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0724 - accuracy: 0.9805 - val_loss: 0.3494 - val_accuracy: 0.8804\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0600 - accuracy: 0.9840 - val_loss: 0.3923 - val_accuracy: 0.8736\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0506 - accuracy: 0.9878 - val_loss: 0.4017 - val_accuracy: 0.8762\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0409 - accuracy: 0.9909 - val_loss: 0.4407 - val_accuracy: 0.8730\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9934 - val_loss: 0.4725 - val_accuracy: 0.8724\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.4912 - val_accuracy: 0.8702\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9957 - val_loss: 0.5915 - val_accuracy: 0.8575\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0185 - accuracy: 0.9973 - val_loss: 0.5732 - val_accuracy: 0.8682\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0155 - accuracy: 0.9980 - val_loss: 0.6033 - val_accuracy: 0.8674\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.6299 - val_accuracy: 0.8669\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.6818 - val_accuracy: 0.8654\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.7029 - val_accuracy: 0.8641\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb # importing the imdb dataset from keras library\n",
        "(train_data, train_labels), _ = imdb.load_data(num_words=10000) # loading the imdb dataset into train_data and train_labels with 10000 words\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000): # defining a function to vectorize the sequences with dimension as 10000 by default because the maximum word index is 10000\n",
        "    results = np.zeros((len(sequences), dimension)) # creating a results array with zeros of shape (len(sequences), dimension) which will be used to store the vectorized sequences\n",
        "    for i, sequence in enumerate(sequences): # iterating through the sequences\n",
        "        results[i, sequence] = 1. # setting the results[i, sequence] as 1 which will be used to vectorize the sequences\n",
        "    return results # returning the results\n",
        "train_data = vectorize_sequences(train_data) # vectorizing the train_data\n",
        "\n",
        "model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "    layers.Dense(16, activation=\"relu\"), # adding a dense layer with 16 neurons and relu activation function (this is the input layer that takes the input and passes it to the hidden layer)\n",
        "    layers.Dense(16, activation=\"relu\"), # adding a dense layer with 16 neurons and relu activation function (this is the hidden layer that takes the input from the input layer and passes it to the output layer)\n",
        "    layers.Dense(1, activation=\"sigmoid\") # adding a dense layer with 1 neuron and sigmoid activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with optimizer as rmsprop which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"binary_crossentropy\", # setting loss function as binary_crossentropy which is used for binary classification problems where the output labels are binary\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "history_original = model.fit(train_data, train_labels, # fitting the model with train_data and train_labels by training the model with the original model which will help the model to generalize better\n",
        "                             epochs=20, batch_size=512, validation_split=0.4) # setting the epochs as 20, batch size as 512 and validation split as 0.4 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RA1ccut4Eqg"
      },
      "source": [
        "**Version of the model with lower capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ozgLU0jC4Eqk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.5962 - accuracy: 0.7624 - val_loss: 0.5083 - val_accuracy: 0.8274\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4397 - accuracy: 0.8751 - val_loss: 0.4089 - val_accuracy: 0.8628\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3462 - accuracy: 0.8995 - val_loss: 0.3509 - val_accuracy: 0.8795\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.2846 - accuracy: 0.9157 - val_loss: 0.3149 - val_accuracy: 0.8835\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.2405 - accuracy: 0.9266 - val_loss: 0.2933 - val_accuracy: 0.8884\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.2079 - accuracy: 0.9351 - val_loss: 0.2802 - val_accuracy: 0.8901\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1824 - accuracy: 0.9433 - val_loss: 0.2739 - val_accuracy: 0.8916\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1616 - accuracy: 0.9519 - val_loss: 0.2725 - val_accuracy: 0.8914\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.9565 - val_loss: 0.2779 - val_accuracy: 0.8876\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1299 - accuracy: 0.9619 - val_loss: 0.2783 - val_accuracy: 0.8904\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1175 - accuracy: 0.9667 - val_loss: 0.2950 - val_accuracy: 0.8828\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1062 - accuracy: 0.9697 - val_loss: 0.2941 - val_accuracy: 0.8851\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9739 - val_loss: 0.3054 - val_accuracy: 0.8832\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9763 - val_loss: 0.3168 - val_accuracy: 0.8813\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0781 - accuracy: 0.9800 - val_loss: 0.3216 - val_accuracy: 0.8853\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9826 - val_loss: 0.3380 - val_accuracy: 0.8791\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9849 - val_loss: 0.3473 - val_accuracy: 0.8821\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0577 - accuracy: 0.9869 - val_loss: 0.3657 - val_accuracy: 0.8786\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0525 - accuracy: 0.9879 - val_loss: 0.3757 - val_accuracy: 0.8782\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9901 - val_loss: 0.4024 - val_accuracy: 0.8733\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "    layers.Dense(4, activation=\"relu\"), # adding a dense layer with 4 neurons and relu activation function (this is the input layer that takes the input and passes it to the hidden layer)\n",
        "    layers.Dense(4, activation=\"relu\"), # adding a dense layer with 4 neurons and relu activation function (this is the hidden layer that takes the input from the input layer and passes it to the output layer)\n",
        "    layers.Dense(1, activation=\"sigmoid\") # adding a dense layer with 1 neuron and sigmoid activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with optimizer as rmsprop which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"binary_crossentropy\", # setting loss function as binary_crossentropy which is used for binary classification problems where the output labels are binary\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "history_smaller_model = model.fit( # fitting the model with train_data and train_labels by training the model with a smaller model which will help the model to generalize better\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4) # setting the epochs as 20, batch size as 512 and validation split as 0.4 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmZoInO14Eql"
      },
      "source": [
        "**Version of the model with higher capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JN7j3LvB4Eql"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 3s 75ms/step - loss: 0.5561 - accuracy: 0.7557 - val_loss: 0.3307 - val_accuracy: 0.8787\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 2s 56ms/step - loss: 0.2428 - accuracy: 0.9035 - val_loss: 0.2752 - val_accuracy: 0.8884\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 2s 55ms/step - loss: 0.1595 - accuracy: 0.9370 - val_loss: 0.3848 - val_accuracy: 0.8715\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 2s 55ms/step - loss: 0.0820 - accuracy: 0.9721 - val_loss: 0.4244 - val_accuracy: 0.8732\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 2s 58ms/step - loss: 0.0873 - accuracy: 0.9780 - val_loss: 0.3710 - val_accuracy: 0.8882\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 2s 58ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5333 - val_accuracy: 0.8838\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 2s 54ms/step - loss: 6.6348e-04 - accuracy: 0.9999 - val_loss: 0.6716 - val_accuracy: 0.8836\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 2s 56ms/step - loss: 0.2168 - accuracy: 0.9811 - val_loss: 0.4909 - val_accuracy: 0.8812\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 2s 54ms/step - loss: 5.3465e-04 - accuracy: 1.0000 - val_loss: 0.5802 - val_accuracy: 0.8840\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 2s 55ms/step - loss: 1.4524e-04 - accuracy: 1.0000 - val_loss: 0.6454 - val_accuracy: 0.8848\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 2s 56ms/step - loss: 5.3301e-05 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.8833\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 2s 55ms/step - loss: 1.6027e-05 - accuracy: 1.0000 - val_loss: 0.8303 - val_accuracy: 0.8830\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 2s 56ms/step - loss: 4.6711e-06 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.8824\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 2s 57ms/step - loss: 1.4312e-06 - accuracy: 1.0000 - val_loss: 0.9965 - val_accuracy: 0.8825\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 2s 54ms/step - loss: 4.5719e-07 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 0.8831\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 2s 55ms/step - loss: 1.6565e-07 - accuracy: 1.0000 - val_loss: 1.1352 - val_accuracy: 0.8849\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 2s 54ms/step - loss: 6.8439e-08 - accuracy: 1.0000 - val_loss: 1.2095 - val_accuracy: 0.8834\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 2s 56ms/step - loss: 3.4009e-08 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.8835\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 2s 55ms/step - loss: 2.1219e-08 - accuracy: 1.0000 - val_loss: 1.2737 - val_accuracy: 0.8835\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 2s 54ms/step - loss: 1.5095e-08 - accuracy: 1.0000 - val_loss: 1.2968 - val_accuracy: 0.8831\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "    layers.Dense(512, activation=\"relu\"), # adding a dense layer with 512 neurons and relu activation function (this is the input layer that takes the input and passes it to the hidden layer)\n",
        "    layers.Dense(512, activation=\"relu\"), # adding a dense layer with 512 neurons and relu activation function (this is the hidden layer that takes the input from the input layer and passes it to the output layer)\n",
        "    layers.Dense(1, activation=\"sigmoid\") # adding a dense layer with 1 neuron and sigmoid activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with optimizer as rmsprop which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"binary_crossentropy\", # setting loss function as binary_crossentropy which is used for binary classification problems where the output labels are binary\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "history_larger_model = model.fit( # fitting the model with train_data and train_labels by training the model with a larger model which will help the model to generalize better\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4) # setting the epochs as 20, batch size as 512 and validation split as 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EsJXpLW4Eql"
      },
      "source": [
        "#### Adding weight regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M283l5-64Eql"
      },
      "source": [
        "**Adding L2 weight regularization to the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BOCB4kaz4Eql"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.6497 - accuracy: 0.6911 - val_loss: 0.5789 - val_accuracy: 0.8453\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4590 - accuracy: 0.8799 - val_loss: 0.4359 - val_accuracy: 0.8616\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3578 - accuracy: 0.9130 - val_loss: 0.3781 - val_accuracy: 0.8856\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3128 - accuracy: 0.9228 - val_loss: 0.3682 - val_accuracy: 0.8829\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2871 - accuracy: 0.9304 - val_loss: 0.3628 - val_accuracy: 0.8863\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2703 - accuracy: 0.9349 - val_loss: 0.3963 - val_accuracy: 0.8687\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2588 - accuracy: 0.9394 - val_loss: 0.3609 - val_accuracy: 0.8866\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2435 - accuracy: 0.9470 - val_loss: 0.4557 - val_accuracy: 0.8520\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2338 - accuracy: 0.9505 - val_loss: 0.4202 - val_accuracy: 0.8655\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2383 - accuracy: 0.9463 - val_loss: 0.4002 - val_accuracy: 0.8741\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2249 - accuracy: 0.9539 - val_loss: 0.3788 - val_accuracy: 0.8797\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2175 - accuracy: 0.9552 - val_loss: 0.4118 - val_accuracy: 0.8690\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2186 - accuracy: 0.9527 - val_loss: 0.4282 - val_accuracy: 0.8639\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2154 - accuracy: 0.9570 - val_loss: 0.4149 - val_accuracy: 0.8730\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2118 - accuracy: 0.9549 - val_loss: 0.3935 - val_accuracy: 0.8799\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2104 - accuracy: 0.9570 - val_loss: 0.3963 - val_accuracy: 0.8789\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2019 - accuracy: 0.9610 - val_loss: 0.4007 - val_accuracy: 0.8780\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1967 - accuracy: 0.9635 - val_loss: 0.4080 - val_accuracy: 0.8785\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2044 - accuracy: 0.9587 - val_loss: 0.4115 - val_accuracy: 0.8771\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1894 - accuracy: 0.9670 - val_loss: 0.5112 - val_accuracy: 0.8561\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers # importing regularizers from keras library\n",
        "model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "    layers.Dense(16, # adding a dense layer with 16 neurons which is the input layer\n",
        "                 kernel_regularizer=regularizers.l2(0.002), # setting the kernel_regularizer as l2 with 0.002 which is used to prevent overfitting by adding a penalty to the loss function\n",
        "                 activation=\"relu\"), # setting the activation function as relu which is used to introduce non-linearity to the model\n",
        "    layers.Dense(16, # adding a dense layer with 16 neurons which is the hidden layer\n",
        "                 kernel_regularizer=regularizers.l2(0.002), # setting the kernel_regularizer as l2 with 0.002 which is used to prevent overfitting by adding a penalty to the loss function\n",
        "                 activation=\"relu\"), # setting the activation function as relu which is used to introduce non-linearity to the model\n",
        "    layers.Dense(1, activation=\"sigmoid\") # adding a dense layer with 1 neuron and sigmoid activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with optimizer as rmsprop which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"binary_crossentropy\", # setting loss function as binary_crossentropy which is used for binary classification problems where the output labels are binary\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "history_l2_reg = model.fit( # fitting the model with train_data and train_labels by training the model with l2 regularization which will help the model to generalize better\n",
        "    train_data, train_labels, \n",
        "    epochs=20, batch_size=512, validation_split=0.4) # setting the epochs as 20, batch size as 512 and validation split as 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTQr10zV4Eql"
      },
      "source": [
        "**Different weight regularizers available in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uHEwjaeV4Eql"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.regularizers.L1L2 at 0x3247d4d10>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers # importing regularizers from keras library\n",
        "regularizers.l1(0.001) # setting the regularizer as l1 with 0.001 which is used to prevent overfitting by adding a penalty to the loss function\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001) # setting the regularizer as l1_l2 with l1 as 0.001 and l2 as 0.001 which is used to prevent overfitting by adding a penalty to the loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MKSOCI94Eql"
      },
      "source": [
        "#### Adding dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4YIjwYa4Eql"
      },
      "source": [
        "**Adding dropout to the IMDB model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Vz4Fk6ei4Eql"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.6391 - accuracy: 0.6365 - val_loss: 0.5331 - val_accuracy: 0.8495\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5227 - accuracy: 0.7647 - val_loss: 0.4421 - val_accuracy: 0.8703\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.8238 - val_loss: 0.3727 - val_accuracy: 0.8787\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8641 - val_loss: 0.3310 - val_accuracy: 0.8766\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3345 - accuracy: 0.8890 - val_loss: 0.3059 - val_accuracy: 0.8858\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2912 - accuracy: 0.9103 - val_loss: 0.2833 - val_accuracy: 0.8887\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2595 - accuracy: 0.9217 - val_loss: 0.2831 - val_accuracy: 0.8905\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2304 - accuracy: 0.9316 - val_loss: 0.3111 - val_accuracy: 0.8878\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.2001 - accuracy: 0.9427 - val_loss: 0.2951 - val_accuracy: 0.8858\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1846 - accuracy: 0.9442 - val_loss: 0.3131 - val_accuracy: 0.8884\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1620 - accuracy: 0.9559 - val_loss: 0.3267 - val_accuracy: 0.8874\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1483 - accuracy: 0.9566 - val_loss: 0.3392 - val_accuracy: 0.8862\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1370 - accuracy: 0.9607 - val_loss: 0.3682 - val_accuracy: 0.8853\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.9646 - val_loss: 0.4267 - val_accuracy: 0.8847\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.9687 - val_loss: 0.4187 - val_accuracy: 0.8855\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.9700 - val_loss: 0.4371 - val_accuracy: 0.8824\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9739 - val_loss: 0.4983 - val_accuracy: 0.8843\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0921 - accuracy: 0.9730 - val_loss: 0.5065 - val_accuracy: 0.8837\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9767 - val_loss: 0.5084 - val_accuracy: 0.8810\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 0.9778 - val_loss: 0.5822 - val_accuracy: 0.8838\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([ # creating a sequential model which is a linear stack of layers that can be created by passing a list of layers to the Sequential class\n",
        "    layers.Dense(16, activation=\"relu\"), # adding a dense layer with 16 neurons and relu activation function (this is the input layer that takes the input and passes it to the hidden layer)\n",
        "    layers.Dropout(0.5), # adding a dropout layer with 0.5 which is used to prevent overfitting by randomly setting the input units to 0 with a frequency of 0.5\n",
        "    layers.Dense(16, activation=\"relu\"), # adding a dense layer with 16 neurons and relu activation function (this is the hidden layer that takes the input from the input layer and passes it to the output layer)\n",
        "    layers.Dropout(0.5), # adding a dropout layer with 0.5 which is used to prevent overfitting by randomly setting the input units to 0 with a frequency of 0.5\n",
        "    layers.Dense(1, activation=\"sigmoid\") # adding a dense layer with 1 neuron and sigmoid activation function (this is the output layer that takes the input from the hidden layer and passes it to the output layer)\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\", # compiling the model with optimizer as rmsprop which is a gradient descent optimization algorithm that is used to update the weights of the model\n",
        "              loss=\"binary_crossentropy\", # setting loss function as binary_crossentropy which is used for binary classification problems where the output labels are binary\n",
        "              metrics=[\"accuracy\"]) # setting the metrics as accuracy which is used to evaluate the performance of the model\n",
        "history_dropout = model.fit( # fitting the model with train_data and train_labels by training the model with dropout regularization which will help the model to generalize better\n",
        "    train_data, train_labels, \n",
        "    epochs=20, batch_size=512, validation_split=0.4) # setting the epochs as 20, batch size as 512 and validation split as 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGLCtv_L4Eql"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter05_fundamentals-of-ml.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
