{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V23eg-ACcpxs"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTuNosLWcpxx"
      },
      "source": [
        "# Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y-uvVdwcpxy"
      },
      "source": [
        "## Key concepts in review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Atuyomt_cpxy"
      },
      "source": [
        "### Various approaches to AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih8m44OOcpxy"
      },
      "source": [
        "### What makes deep learning special within the field of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6xot71Gcpxy"
      },
      "source": [
        "### How to think about deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VV7tPcAcpxz"
      },
      "source": [
        "### Key enabling technologies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-1wYUrMcpxz"
      },
      "source": [
        "### The universal machine-learning workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNPdFAdUcpx0"
      },
      "source": [
        "### Key network architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc3FQazUcpx0"
      },
      "source": [
        "#### Densely connected networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rihr6zk-cpx0"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras # importing keras from tensorflow\n",
        "from tensorflow.keras import layers # importing layers from tensorflow.keras\n",
        "inputs = keras.Input(shape=(num_input_features,)) # defining input layer\n",
        "x = layers.Dense(32, activation=\"relu\")(inputs) # defining hidden layer\n",
        "x = layers.Dense(32, activation=\"relu\")(x) # defining hidden layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # defining output layer with sigmoid activation\n",
        "model = keras.Model(inputs, outputs) # defining model\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\") # compiling model with optimizer and loss function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE_r1TY5cpx0"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_input_features,)) # defining input layer\n",
        "x = layers.Dense(32, activation=\"relu\")(inputs) # defining hidden layer\n",
        "x = layers.Dense(32, activation=\"relu\")(x) # defining hidden layer\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x) # defining output layer with softmax activation\n",
        "model = keras.Model(inputs, outputs) # defining model\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\") # compiling model with optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXfxrKsgcpx0"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_input_features,)) # defining input layer\n",
        "x = layers.Dense(32, activation=\"relu\")(inputs) # defining hidden layer\n",
        "x = layers.Dense(32, activation=\"relu\")(x) # defining hidden layer\n",
        "outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x) # defining output layer with sigmoid activation function\n",
        "model = keras.Model(inputs, outputs) # defining model\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\") # compiling model with optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rxOhwP5cpx1"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_input_features,)) # defining input layer\n",
        "x = layers.Dense(32, activation=\"relu\")(inputs) # defining hidden layer\n",
        "x = layers.Dense(32, activation=\"relu\")(x) # defining hidden layer\n",
        "outputs layers.Dense(num_values)(x) # defining output layer\n",
        "model = keras.Model(inputs, outputs) # defining model\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\") # compiling model with optimizer and loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvD8cW2qcpx1"
      },
      "source": [
        "#### Convnets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ny_7E__qcpx1"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(height, width, channels)) # defining input layer\n",
        "x = layers.SeparableConv2D(32, 3, activation=\"relu\")(inputs) # defining hidden layer\n",
        "x = layers.SeparableConv2D(64, 3, activation=\"relu\")(x) # defining hidden layer\n",
        "x = layers.MaxPooling2D(2)(x) # defining hidden layer\n",
        "x = layers.SeparableConv2D(64, 3, activation=\"relu\")(x) # defining hidden layer\n",
        "x = layers.SeparableConv2D(128, 3, activation=\"relu\")(x) # defining hidden layer\n",
        "x = layers.MaxPooling2D(2)(x) # defining hidden layer\n",
        "x = layers.SeparableConv2D(64, 3, activation=\"relu\")(x) # defining hidden layer\n",
        "x = layers.SeparableConv2D(128, 3, activation=\"relu\")(x) # defining hidden layer\n",
        "x = layers.GlobalAveragePooling2D()(x) # defining hidden layer\n",
        "x = layers.Dense(32, activation=\"relu\")(x) # defining hidden layer\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x) # defining output layer with softmax activation\n",
        "model = keras.Model(inputs, outputs) # defining model\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\") # compiling model with optimizer and loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AavoN8ERcpx1"
      },
      "source": [
        "#### RNNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6susp8Nocpx1"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_timesteps, num_features)) # defining input layer\n",
        "x = layers.LSTM(32)(inputs) # defining hidden layer\n",
        "outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x) # defining output layer with sigmoid activation\n",
        "model = keras.Model(inputs, outputs) # defining model\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\") # compiling model with optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4HyTAgXcpx1"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(num_timesteps, num_features)) # defining input layer\n",
        "x = layers.LSTM(32, return_sequences=True)(inputs) # defining hidden layer\n",
        "x = layers.LSTM(32, return_sequences=True)(x) # defining hidden layer\n",
        "x = layers.LSTM(32)(x) # defining hidden layer\n",
        "outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x) # defining output layer with sigmoid activation\n",
        "model = keras.Model(inputs, outputs) # defining model\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\") # compiling model with optimizer and loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4baHuj2cpx1"
      },
      "source": [
        "#### Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I51OA2ZZcpx1"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = keras.Input(shape=(sequence_length,), dtype=\"int64\") # defining input layer\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs) # defining hidden layer\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) # defining hidden layer\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\") # defining input layer\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs) # defining hidden layer\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs) # defining hidden layer\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x) # defining output layer with softmax activation\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs) # defining model\n",
        "transformer.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\") # compiling model with optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5FecuI-cpx1"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(sequence_length,), dtype=\"int64\") # defining input layer\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs) # defining hidden layer\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) # defining hidden layer\n",
        "x = layers.GlobalMaxPooling1D()(x) # defining hidden layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # defining output layer with sigmoid activation\n",
        "model = keras.Model(inputs, outputs) # defining model\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\") # compiling model with optimizer and loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXe8lL5Ucpx2"
      },
      "source": [
        "### The space of possibilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H-Ij_WEcpx2"
      },
      "source": [
        "## The limitations of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4l9--Jqcpx2"
      },
      "source": [
        "### The risk of anthropomorphizing machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeV-AN0gcpx2"
      },
      "source": [
        "### Automatons vs. intelligent agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si9pP0iJcpx2"
      },
      "source": [
        "### Local generalization vs. extreme generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTxJU1hEcpx2"
      },
      "source": [
        "### The purpose of intelligence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXEJQWdScpx2"
      },
      "source": [
        "### Climbing the spectrum of generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWyieWT4cpx2"
      },
      "source": [
        "## Setting the course toward greater generality in AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKp345Dycpx2"
      },
      "source": [
        "### On the importance of setting the right objective: The shortcut rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQRZQAGOcpx2"
      },
      "source": [
        "### A new target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CscNMv_Scpx2"
      },
      "source": [
        "## Implementing intelligence: The missing ingredients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHAHCnrGcpx2"
      },
      "source": [
        "### Intelligence as sensitivity to abstract analogies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92pUnR4tcpx2"
      },
      "source": [
        "### The two poles of abstraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb80yo9Rcpx2"
      },
      "source": [
        "#### Value-centric analogy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQYCfie6cpx2"
      },
      "source": [
        "#### Program-centric analogy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fizpWx0Icpx2"
      },
      "source": [
        "#### Cognition as a combination of both kinds of abstraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulzY0Hh0cpx2"
      },
      "source": [
        "### The missing half of the picture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJAzt1ePcpx2"
      },
      "source": [
        "## The future of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U75I7wafcpx3"
      },
      "source": [
        "### Models as programs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnH4fIOQcpx3"
      },
      "source": [
        "### Blending together deep learning and program synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOBd8unicpx3"
      },
      "source": [
        "#### Integrating deep-learning modules and algorithmic modules into hybrid systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "junRTcDycpx3"
      },
      "source": [
        "#### Using deep learning to guide program search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vytXZAJcpx3"
      },
      "source": [
        "### Lifelong learning and modular subroutine reuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypILreWOcpx3"
      },
      "source": [
        "### The long-term vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avee51Wycpx3"
      },
      "source": [
        "## Staying up to date in a fast-moving field"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO0clltscpx3"
      },
      "source": [
        "### Practice on real-world problems using Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT5abZ0Kcpx3"
      },
      "source": [
        "### Read about the latest developments on arXiv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-eipcfNcpx3"
      },
      "source": [
        "### Explore the Keras ecosystem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq98HJGZcpx3"
      },
      "source": [
        "## Final words"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter14_conclusions.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
